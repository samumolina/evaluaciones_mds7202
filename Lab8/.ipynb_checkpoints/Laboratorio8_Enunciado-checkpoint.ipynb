{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-7111e3ae-b60e-4569-b774-a13ef1b95f77",
    "deepnote_cell_height": 156.390625,
    "deepnote_cell_type": "markdown",
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 8: ¿Superhéroe o Villano? 🦸</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-988ebcea-7685-4ad4-968d-5530ff0099a7",
    "deepnote_cell_height": 165.171875,
    "deepnote_cell_type": "markdown",
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Patricio Ortiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-038ebafa-6641-4c2a-b2e8-62ad2018b88e",
    "deepnote_cell_height": 171.78125,
    "deepnote_cell_type": "markdown",
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: Samuel Molina Bustos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-913d0cc4-e146-4ff9-a0e3-26a20c808d7c",
    "deepnote_cell_height": 63,
    "deepnote_cell_type": "markdown",
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** `https://github.com/samumolina/evaluaciones_mds7202`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-64f7c2d0-4287-4f3a-9b4b-2c5b829f606c",
    "deepnote_cell_height": 651.640625,
    "deepnote_cell_type": "markdown",
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "## Temas a tratar\n",
    "\n",
    "- Codificación de texto usando Bag of Words.\n",
    "- Búsqueda del modelo óptimo de clasificación usando `GridSearch`\n",
    "- Uso de pipelines.\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- Fecha de entrega: 23/06/2022\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deberán realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Obtener caracteristicas a partir de texto usando `CountVectorizer`.\n",
    "- Fijar un pipeline con un modelo base que luego se irá optimizando.\n",
    "- Comprender cómo realizar una búsqueda de grilla sobre un conjunto de clasificadores e hiperparámetros usando `GridSearch`.\n",
    "\n",
    "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-b8353b3b-8f85-4aa6-9379-96902d3d0bf3",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 😸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T00:08:16.884674Z",
     "start_time": "2021-03-29T00:08:16.349846Z"
    },
    "cell_id": "00007-e696189c-3187-4899-bf04-8034b0e8a595",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 1509.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 9106,
     "status": "ok",
     "timestamp": 1625497725070,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "execution_millis": 36497,
    "execution_start": 1637348694866,
    "id": "uyc33dKdzAHy",
    "outputId": "14d5da48-5dae-4ce4-a8ba-b826ea91a126",
    "source_hash": "7ce9748b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (5.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (1.0.2)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (0.55.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (1.22.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (4.64.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (0.5.7)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from umap-learn) (1.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from numba>=0.49->umap-learn) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from numba>=0.49->umap-learn) (0.38.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from tqdm->umap-learn) (0.4.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librería Core del lab.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Pre-procesamiento\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Clasifación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metricas de evaluación\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Librería para plotear\n",
    "!pip install --upgrade plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Proyecciones en baja dimensionalidad: UMAP\n",
    "!pip install umap-learn\n",
    "\n",
    "# Librería para NLP\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-9c535dd9-01e0-4804-a325-7b5d36a20a32",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. ¿Quien es Bat Cow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-43ac5618-611f-4712-aec7-faaa53d72d08",
    "deepnote_cell_height": 347.8125,
    "deepnote_cell_type": "markdown",
    "id": "3Q93vbNS25bM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.imgur.com/D9f1RHy.jpg\" width=\"350\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-632e9494-ce9c-4d54-8e57-e700baed4302",
    "deepnote_cell_height": 503.03125,
    "deepnote_cell_type": "markdown",
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "En vez de estar desarrollando las evaluaciones correspondientes a su curso, su profesor de catedra y su auxiliar discuten acerca la alineación (héroe o villano) del personaje de ficción Bat-Cow. \n",
    "\n",
    "El cuerpo docente, no logra ponerse de acuerdo si el personaje es bueno, neutral o malo: el auxiliar plantea que Bat-cow posee una siniestra mirada, intrigante pero común característica de los personajes malvados. \n",
    "Por otra parte, extendiendo las ideas de Rousseau, el profesor plantea que tal como los humanos no nacen malos, no existe motivo por el cual una vaca con superpoderes deba serlo.\n",
    "\n",
    "Sin embargo, ambos concuerdan que es difícil estimar la alineación solo usando los atributos físicos, por lo que creen el análisis debe ser complementado aún más antes de comunicarle los resultados a su estudiantado. Buscando más información, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineación: la historia personal de cada superhéroe o villano.\n",
    "\n",
    "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineación de cada personaje basado en su historia personal.\n",
    "\n",
    "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servirá para entrenar un modelo de clasificación, mientras que el segundo es un dataset con personajes de ficción no etiquetados a predecir (sí, aquí está la misteriosa Batcow).\n",
    "\n",
    "Para comenzar cargue los dataset señalados y visualice a través de un head los atributos que poseen cada uno de los dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00011-9a36781e-c26a-46de-b4bf-a5448a347cab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 220.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1625497735673,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "execution_millis": 27,
    "execution_start": 1637348657022,
    "id": "Jqq-s010Iwl1",
    "outputId": "bc29f770-d066-4443-8cee-00e3db46c629",
    "source_hash": "c60dc4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorando conexión drive-colab\n"
     ]
    }
   ],
   "source": [
    "# Si usted está utilizando Colabolatory le puede ser útil este código para cargar los archivos.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    path = 'Dirección donde tiene los archivos en el Drive'\n",
    "except: \n",
    "    print('Ignorando conexión drive-colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00012-8b0c36c2-aeaa-4ba1-9611-45f0599aa584",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1625499009249,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "execution_millis": 325,
    "execution_start": 1637348732856,
    "id": "bED3w3tDbSCf",
    "source_hash": "443d6e8"
   },
   "outputs": [],
   "source": [
    "df_comics = pd.read_csv('df_comics.csv')\n",
    "df_comics_no_label = pd.read_csv('comics_no_label.csv')\n",
    "df_comics = df_comics.dropna(subset=['history_text']) # eliminar ejemplos sin historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00013-2cd3a433-4f43-4a9e-92f5-caf54a662db2",
    "deepnote_cell_height": 323.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     208.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 654,
    "execution_start": 1637348731943,
    "source_hash": "b986316d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>real_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>history_text</th>\n",
       "      <th>powers_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>...</th>\n",
       "      <th>has_flight</th>\n",
       "      <th>has_accelerated_healing</th>\n",
       "      <th>has_weapons_master</th>\n",
       "      <th>has_intelligence</th>\n",
       "      <th>has_reflexes</th>\n",
       "      <th>has_super_speed</th>\n",
       "      <th>has_durability</th>\n",
       "      <th>has_stamina</th>\n",
       "      <th>has_agility</th>\n",
       "      <th>has_super_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3-D Man</td>\n",
       "      <td>Delroy Garrett, Jr.</td>\n",
       "      <td>Delroy Garrett, Jr.</td>\n",
       "      <td>6</td>\n",
       "      <td>Delroy Garrett, Jr. grew up to become a track ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A-Bomb</td>\n",
       "      <td>Richard Milhouse Jones</td>\n",
       "      <td>Richard Milhouse Jones</td>\n",
       "      <td>20</td>\n",
       "      <td>Richard \"Rick\" Jones was orphaned at a young ...</td>\n",
       "      <td>On rare occasions, and through unusual circu...</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aa</td>\n",
       "      <td>Aa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>Aa is one of the more passive members of the P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aaron Cash</td>\n",
       "      <td>Aaron Cash</td>\n",
       "      <td>Aaron Cash</td>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Cash is the head of security at Arkham A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aayla Secura</td>\n",
       "      <td>Aayla Secura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>ayla Secura was a Rutian Twi'lek Jedi Knight (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          name               real_name               full_name  \\\n",
       "0           0       3-D Man     Delroy Garrett, Jr.     Delroy Garrett, Jr.   \n",
       "1           2        A-Bomb  Richard Milhouse Jones  Richard Milhouse Jones   \n",
       "2           3            Aa                      Aa                     NaN   \n",
       "3           4    Aaron Cash              Aaron Cash              Aaron Cash   \n",
       "4           5  Aayla Secura            Aayla Secura                     NaN   \n",
       "\n",
       "  overall_score                                       history_text  \\\n",
       "0             6  Delroy Garrett, Jr. grew up to become a track ...   \n",
       "1            20   Richard \"Rick\" Jones was orphaned at a young ...   \n",
       "2            12  Aa is one of the more passive members of the P...   \n",
       "3             5  Aaron Cash is the head of security at Arkham A...   \n",
       "4             8  ayla Secura was a Rutian Twi'lek Jedi Knight (...   \n",
       "\n",
       "                                         powers_text  intelligence_score  \\\n",
       "0                                                NaN                  85   \n",
       "1    On rare occasions, and through unusual circu...                  80   \n",
       "2                                                NaN                  80   \n",
       "3                                                NaN                  80   \n",
       "4                                                NaN                  90   \n",
       "\n",
       "   strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
       "0              30           60  ...         0.0                      0.0   \n",
       "1             100           80  ...         0.0                      1.0   \n",
       "2              50           55  ...         0.0                      0.0   \n",
       "3              10           25  ...         0.0                      0.0   \n",
       "4              40           45  ...         0.0                      1.0   \n",
       "\n",
       "   has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
       "0                 0.0              0.0          0.0             1.0   \n",
       "1                 0.0              0.0          1.0             1.0   \n",
       "2                 0.0              0.0          0.0             0.0   \n",
       "3                 1.0              0.0          0.0             0.0   \n",
       "4                 0.0              0.0          0.0             0.0   \n",
       "\n",
       "  has_durability has_stamina has_agility has_super_strength  \n",
       "0            0.0         0.0         0.0                1.0  \n",
       "1            1.0         1.0         1.0                1.0  \n",
       "2            0.0         0.0         0.0                0.0  \n",
       "3            0.0         0.0         0.0                0.0  \n",
       "4            0.0         0.0         1.0                0.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# queda a labor de su equipo hacer el análisis exploratorio\n",
    "df_comics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-00e51eac-6169-4978-9714-ee8c7a8f55b8",
    "deepnote_cell_height": 410,
    "deepnote_cell_type": "markdown",
    "id": "i4tFPrFA4_O5"
   },
   "source": [
    "## 1.1 Obtención de Features y Bag of Words\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-528c8f39-a27a-40e0-8de0-0cc7f362b4ae",
    "deepnote_cell_height": 561.859375,
    "deepnote_cell_type": "markdown",
    "id": "f_4NF0_V5XZ-"
   },
   "source": [
    "Primero que todo, deben obtener un vector de características del atributo `history_text`, utilizando `Bag of Words`. En este atributo se presenta una breve descripción de la historia de cada uno de los personajes de ficción presentes en el dataset. \n",
    "\n",
    "Pero... antes de empezar, ¿Que es `Bag of Words`?...\n",
    "\n",
    "`Bag of Words` es un modelo de conteo utilizado en Procesamiento de Lenguaje Natural (NLP) que tiene como objetivo generar una representación vectorial (vector de características en nuestro cas) para cada documento a través del conteo de las palabras que contienen. \n",
    "\n",
    "La siguiente figura muestra un ejemplo de `Bag of Words` en acción:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://user.oc-static.com/upload/2020/10/23/16034397439042_surfin%20bird%20bow.png\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "Como pueden ver, el modelo de `Bag of Words` no resulta tan complicado, ¿pero cómo lo aplicamos en python?. \n",
    "\n",
    "Como podrán darse cuenta del ejemplo anterior, para facilitar el conteo será necesario transformar cada uno de los documentos en vectores, donde cada una de las posiciones posee un carácter. Este proceso es conocido como **tokenización** y lo podemos realizar de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00015-5924cc55-1587-4776-8c5e-cb400ddacaa3",
    "deepnote_cell_height": 227.375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     40.375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1637346921830,
    "source_hash": "57e4888a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
       " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()\n",
    "import nltk\n",
    "\n",
    "docs = ['The teacher rocks like a good rock & roll',\n",
    "             'the rock is the best actor in the world']\n",
    "\n",
    "\n",
    "docs_tokenizados = [word_tokenize(doc)  for doc in docs]\n",
    "docs_tokenizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-649b0384-cac3-4b79-93ff-75aac3b8c5df",
    "deepnote_cell_height": 424.125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Podemos mejorar un poco más el proceso de tokenización agregando \n",
    "\n",
    "- Stemming:  Definimos Stemming como un algoritmo basado en reglas que transforma las palabras a una forma general. Un ejemplo de stemming, es el siguiente:\n",
    "- Eliminación de Stopwords: Eliminación de palabras muy frecuentes que entorpecen la clasificación (por ejemplo, el, la los, la, etc...)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://devopedia.org/images/article/218/8583.1569386710.png\" width=\"300\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00017-52acaa25-55d2-49ee-a6c8-49437b8d4523",
    "deepnote_cell_height": 690.9375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     59.5625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 36,
    "execution_start": 1637346924545,
    "source_hash": "d7f59237",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n",
       " ['rock', 'best', 'actor', 'world'],\n",
       " ['new', 'york', 'beauti', 'citi']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos algunas stopword que queremos que sean eliminadas\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english') # CAMBIÉ DE SPANISH A ENGLISH\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "# Inicializamos tokenizador\n",
    "tokenizador = StemmerTokenizer()\n",
    "\n",
    "# Creamos algunos documentos\n",
    "docs = ['The teacher rocks like a good rock & roll',\n",
    "        'the rock is the best actor in the world',\n",
    "        'New York is a beautiful city']\n",
    "\n",
    "# Obtenemos el token del primer documento\n",
    "[tokenizador(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00018-03a0f079-19df-42cb-b3b9-863a9e2ecb7a",
    "deepnote_cell_height": 192.5625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     59.5625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1637346927213,
    "source_hash": "2503a9b4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
       " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
       " ['New', 'York', 'is', 'a', 'beautiful', 'city']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparación con el caso anterior\n",
    "docs_tokenizados = [word_tokenize(doc) for doc in docs]\n",
    "docs_tokenizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-3f862033-7b4e-4623-b17f-545b988af69b",
    "deepnote_cell_height": 110.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Al Estilo Scikit\n",
    "\n",
    "Scikit implementa `bag of words` a través de la clase `CountVectorizer()` la cual contiene muchas opciones para mejorar la tokenización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00020-721a6ba0-0990-4436-9de5-4b4b53c5ff79",
    "deepnote_cell_height": 270,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     119
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 152,
    "execution_start": 1637346927803,
    "source_hash": "2bc7124d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&amp;</th>\n",
       "      <th>actor</th>\n",
       "      <th>beauti</th>\n",
       "      <th>best</th>\n",
       "      <th>citi</th>\n",
       "      <th>good</th>\n",
       "      <th>like</th>\n",
       "      <th>new</th>\n",
       "      <th>rock</th>\n",
       "      <th>roll</th>\n",
       "      <th>teacher</th>\n",
       "      <th>world</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   &  actor  beauti  best  citi  good  like  new  rock  roll  teacher  world  \\\n",
       "0  1      0       0     0     0     1     1    0     2     1        1      0   \n",
       "1  0      1       0     1     0     0     0    0     1     0        0      1   \n",
       "2  0      0       1     0     1     0     0    1     0     0        0      0   \n",
       "\n",
       "   york  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer(tokenizer= StemmerTokenizer())\n",
    "df = bow.fit_transform(docs)\n",
    "\n",
    "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-b3e721d0-6b1f-4f91-aef8-7b04028286fe",
    "deepnote_cell_height": 155.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Una de las cosas más interesantes que provee son el use de n-gramas, los cuales, en palabras simples, son conjuntos de n-palabras que se concatenan entre si y que se consideran como tokens separados. \n",
    "\n",
    "Pensemos en `Nueva York`. Cuando se tokeniza Nueva York, se generan dos tokens independientes que a simple vista no tienen relación: `Nueva` `York`.\n",
    "Al usar n-gramas (en un rango min=1,max=2) , generamos tanto `Nueva` y `York` como también `Nueva York` como un token independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00022-a7abf0fb-cbf2-4745-a96a-dcad9d4bc00f",
    "deepnote_cell_height": 301.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     150.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 241,
    "execution_start": 1637346930092,
    "source_hash": "6af25c7e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&amp;</th>\n",
       "      <th>&amp; roll</th>\n",
       "      <th>actor</th>\n",
       "      <th>actor world</th>\n",
       "      <th>beauti</th>\n",
       "      <th>beauti citi</th>\n",
       "      <th>best</th>\n",
       "      <th>best actor</th>\n",
       "      <th>citi</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>rock</th>\n",
       "      <th>rock &amp;</th>\n",
       "      <th>rock best</th>\n",
       "      <th>rock like</th>\n",
       "      <th>roll</th>\n",
       "      <th>teacher</th>\n",
       "      <th>teacher rock</th>\n",
       "      <th>world</th>\n",
       "      <th>york</th>\n",
       "      <th>york beauti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   &  & roll  actor  actor world  beauti  beauti citi  best  best actor  citi  \\\n",
       "0  1       1      0            0       0            0     0           0     0   \n",
       "1  0       0      1            1       0            0     1           1     0   \n",
       "2  0       0      0            0       1            1     0           0     1   \n",
       "\n",
       "   good  ...  rock  rock &  rock best  rock like  roll  teacher  teacher rock  \\\n",
       "0     1  ...     2       1          0          1     1        1             1   \n",
       "1     0  ...     1       0          1          0     0        0             0   \n",
       "2     0  ...     0       0          0          0     0        0             0   \n",
       "\n",
       "   world  york  york beauti  \n",
       "0      0     0            0  \n",
       "1      1     0            0  \n",
       "2      0     1            1  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
    "df = bow.fit_transform(docs)\n",
    "\n",
    "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-55bca23d-f3d4-4f39-ae9d-e8810b522c79",
    "deepnote_cell_height": 97.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "De los resultados, podemos ver que generamos vectores de conteo para cada una de las palabras que conforman el corpus.  Un punto extra que se agrega en esta obtención de frecuencias son los bigramas, que básicamente son el conjunto de palabras de tamaño de aparecen juntas en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-231f49a8-163f-457d-b933-9e5dad0e1e29",
    "deepnote_cell_height": 547,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Codificando los Super{heroes, villanos}  [0.5 Puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://c.tenor.com/LkQzw7k5DV4AAAAd/anime-hacking.gif\" width=\"300\">\n",
    "</p>\n",
    "\n",
    "Conociendo ahora que es el proceso de `bag of words`, aplique este modelo de obtención de caracteristicas de la siguiente forma en un pipeline:\n",
    "\n",
    "- Utilice el tokenizador entregado.\n",
    "- Obtenga caracteristicas de los unigramas y bigramas del texto (tal como el ejemplo).\n",
    "\n",
    "```python\n",
    "bog = CountVectorizer(tokenizer= StemmerTokenizer(),`\n",
    "                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
    "                      )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-145bb273-d73c-4ad1-8b84-46327add3a2e",
    "deepnote_cell_height": 332.90625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
    "\n",
    "```python\n",
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
    "```\n",
    "\n",
    "No es necesario que obtenga un dataframe en concreto con las características solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
    "\n",
    "**To-Do:**\n",
    "- [ ] Obtener a traves de Bag of Words (`CountVectorizer`) caracteristicas del resumen de historia de cada personaje.\n",
    "- [ ] Aplicar `MinMaxScaler` sobre los atributos de interes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-b13521a0-adf9-4c19-893e-ba6ed644ca12",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00026-898e0ee0-748d-4dac-bfc5-d72f4fe21827",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "ay080DunHcOS"
   },
   "outputs": [],
   "source": [
    "#### Código aquí ####\n",
    "\n",
    "# Variable a tokenizar\n",
    "categorical_features = 'history_text'\n",
    "\n",
    "# Variables númericas\n",
    "atributos_de_interes = ['intelligence_score',\n",
    "                        'strength_score', \n",
    "                        'speed_score',\n",
    "                        'durability_score',\n",
    "                        'power_score',\n",
    "                        'combat_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns transformer\n",
    "preprocessing_transformer = ColumnTransformer(transformers=[\n",
    "    \n",
    "                ('bow', CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2)), categorical_features),\n",
    "                ('MinMaxScaler', MinMaxScaler(), atributos_de_interes),\n",
    "                \n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-0baf6cdb-9550-4717-87db-9f9900d5b276",
    "deepnote_cell_height": 317.5,
    "deepnote_cell_type": "markdown",
    "id": "stHncQ-A-j4I",
    "owner_user_id": "d50c3174-babb-4861-9c71-7e3af66458b8"
   },
   "source": [
    "## 1.2 Diseño de Baseline y  Primer Entrenamiento  [1 Puntos]\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-1452da19-1559-4b8b-8b73-a134157c0656",
    "deepnote_cell_height": 455.859375,
    "deepnote_cell_type": "markdown",
    "id": "NeMiptpQ_EWb"
   },
   "source": [
    "\n",
    "Genere un Pipeline con las caracteristicas solicitadas en la sección 1.1, un selector de mejores features `SelectPercentile` con métrica `f_classif` y percentile=90 y un clasificador `MultinomialNB()` por defecto.\n",
    "\n",
    "Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde las etiquetas estará dado por el atributo `alignment`. \n",
    "\n",
    "Entrene el modelo y reporte el desempeño con un `classification_report`. ¿ Nos recomendaría predecir la alineación de BatCow con este clasificador?.\n",
    "\n",
    "Finalmente, compare el modelo entrenado con un modelo Dummy estratificado y responda: ¿El clasificador entrenado es mejor que el dummy que entrega respuestas al azar?\n",
    "\n",
    "**To-do:**\n",
    "- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1, ejecutar holdout y aplicar un clasificador `MultinomialNB()`.\n",
    "- [ ] Entrenar el pipeline, calcular el `classification_report` asociado y comentar los resultados.\n",
    "- [ ] Entrenar un `DummyClassifier` con estrategia `statified`, calcular el `classification_report` asociado y comentar que implican los scores obtenidos en comparación con los resultados del baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-34f1be30-f2df-45ac-aa14-8e05dc678be9",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00031-92f07569-b6ee-48af-be9e-70cd05cb9e5e",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "_hHpPDooPafy"
   },
   "outputs": [],
   "source": [
    "#### Código aquí ####\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "baseline_pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocesamiento\", preprocessing_transformer), \n",
    "        (\"Selection\", SelectPercentile(f_classif, percentile=90)),\n",
    "        (\"Bayes\", MultinomialNB())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout\n",
    "\n",
    "labels = df_comics.loc[:, 'alignment']\n",
    "features = df_comics.drop(columns=['alignment'])[['history_text',\n",
    "                                                'intelligence_score',\n",
    "                                                'strength_score', \n",
    "                                                'speed_score',\n",
    "                                                'durability_score',\n",
    "                                                'power_score',\n",
    "                                                'combat_score']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.33,\n",
    "    random_state=50,\n",
    "    shuffle=True,\n",
    "    stratify=labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alignment\n",
       "Good         743\n",
       "Bad          429\n",
       "Neutral      113\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conteo de clases\n",
    "df_comics[['alignment']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conteo en train: Counter({'Good': 497, 'Bad': 287, 'Neutral': 76})\n",
      "conteo en test: Counter({'Good': 246, 'Bad': 142, 'Neutral': 37})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(f'conteo en train: {Counter(y_train)}')\n",
    "print(f'conteo en test: {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocesamiento',\n",
       "                 ColumnTransformer(transformers=[('bow',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       "                                                  'history_text'),\n",
       "                                                 ('MinMaxScaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['intelligence_score',\n",
       "                                                   'strength_score',\n",
       "                                                   'speed_score',\n",
       "                                                   'durability_score',\n",
       "                                                   'power_score',\n",
       "                                                   'combat_score'])])),\n",
       "                ('Selection', SelectPercentile(percentile=90)),\n",
       "                ('Bayes', MultinomialNB())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se entrena pipeline base\n",
    "\n",
    "baseline_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "\n",
    "y_pred = baseline_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.11      0.75      0.19        20\n",
      "        Good       0.99      0.60      0.75       403\n",
      "     Neutral       0.05      1.00      0.10         2\n",
      "\n",
      "    accuracy                           0.61       425\n",
      "   macro avg       0.38      0.78      0.35       425\n",
      "weighted avg       0.94      0.61      0.72       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reporte de métricas de evaluación \n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    En accuracy se obtiene 0.61. Solo la clase Good muestra buenos resultados en las métricas precision, recall y f1-score. Este no es un buen clasificador, pero de todas formas es un punto de partida que tiene mucha oportunidad de mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificador Dummy\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"Preprocessing\", preprocessing_transformer),\n",
    "        (\"Selection\", SelectPercentile(f_classif, percentile=90)),\n",
    "        (\"Tree\", DummyClassifier(strategy=\"stratified\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Preprocessing',\n",
       "                 ColumnTransformer(transformers=[('bow',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       "                                                  'history_text'),\n",
       "                                                 ('MinMaxScaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['intelligence_score',\n",
       "                                                   'strength_score',\n",
       "                                                   'speed_score',\n",
       "                                                   'durability_score',\n",
       "                                                   'power_score',\n",
       "                                                   'combat_score'])])),\n",
       "                ('Selection', SelectPercentile(percentile=90)),\n",
       "                ('Tree', DummyClassifier(strategy='stratified'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se entrena pipeline dummy\n",
    "\n",
    "dummy_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "\n",
    "y_pred_dummy = dummy_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.37      0.35      0.36       148\n",
      "        Good       0.56      0.58      0.57       237\n",
      "     Neutral       0.05      0.05      0.05        40\n",
      "\n",
      "    accuracy                           0.45       425\n",
      "   macro avg       0.33      0.33      0.33       425\n",
      "weighted avg       0.44      0.45      0.45       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reporte de métricas de evaluación \n",
    "\n",
    "print(classification_report(y_pred_dummy, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "806813f6a2114d46a6165a97c8c483a0",
    "deepnote_cell_height": 70.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "```\n",
    "Los resultados del clasificador dummy muestran que el clasificador base es considerablemente mejor y también que un clasificador al azar no sirve para clasificar adecuadamente.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-35040b90-b6b9-4e43-8eff-15b7fa897575",
    "deepnote_cell_height": 400,
    "deepnote_cell_type": "markdown",
    "id": "pfm7I2B7_rfB"
   },
   "source": [
    "## 1.3 Busqueda del Mejor Modelo con Grid Search [4 Puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-c58166cc-71f7-4fa3-94c8-c67d1145ccf1",
    "deepnote_cell_height": 859.5,
    "deepnote_cell_type": "markdown",
    "id": "14siiavzK67p"
   },
   "source": [
    "No conformes con el rendimiento obtenido en la sección 1.2, el cuerpo docente les pide que realicen un **`HalvingGridSearchCV`** con diferentes parámetros para mejorar el rendimiento de la clasificación. Para esto, se le solicita que defina:\n",
    "\n",
    "- Tres clasificadores distintos en donde varie sus parámetros. Considere usar modelos clásicos como también los basados en ensamblaje.\n",
    "- Modificar `n-gram` range del `CountVectorizer` probando `(1,1), (1,2) y (1,3)`. Examinar también los otros parámetros de CountVectorizer como por ejemplo `max_df`, `min_df`, etc... ([Documentación aquí](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))\n",
    "- Seleccionar las columnas que contribuyen con la mayor información para la clasificación con `SelectPercentile` en los percentiles `[20, 40, 60, 80]` (puede usar la métrica que usted quiera).\n",
    "- Reporte la mejor combinación encontrada y justifique por qué cree que es la mejor según el clasificador usado, la cantidad de columnas seleccionadas y los parámetros de CountVectorizer seleccionados por GridSearch.\n",
    "\n",
    "A continuación, un ejemplo de parametros para GridSearch para una búsqueda de 3 clasificadores distintos:\n",
    "\n",
    "```python\n",
    "params = [\n",
    "       # clasificador 1 + hiperparámetros\n",
    "       {'clf': classificator1(),\n",
    "        'clf__penalty': ['ovr'],\n",
    "       # clasificador 1 + hiperparámetros    \n",
    "       {'clf': classificator2(),\n",
    "        'clf__n_estimators': [200]},\n",
    "       # clasificador 1 + hiperparámetros\n",
    "       {'clf': classificator3(),\n",
    "        ...\n",
    "       }\n",
    "       ]\n",
    "```\n",
    "\n",
    "**Nota 1**: Puede ver los parámetros modificables aplicando el método get_params() sobre su pipeline. Ver la clase de GridSearch para mayor información sobre la sintáxis de las grillas.\n",
    "\n",
    "**Nota 2**: Recuerde inicializar los clasificadores con un random state definido.\n",
    "\n",
    "**Nota 3**: Puede usar en `HalvingGridSearchCV` el parámetro `verbose=10` para ver que GridSearch le indique el estado de su ejecución.\n",
    "\n",
    "**Nota 3:** El GridSearch puede tomar tiempos de búsqueda exorbitantes, por lo que se le recomienda no agrandar mucho el espacio de búsqueda, dejar corriendo el código y tomarse un tecito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-3fea06e0-a390-4ae0-8036-f5fedb6d6baf",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00037-8b06a200-cb7a-485a-b11b-31a3d0ee57f3",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "oNvHOHELUoIv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessing',\n",
       "   ColumnTransformer(transformers=[('bow',\n",
       "                                    CountVectorizer(ngram_range=(1, 2),\n",
       "                                                    tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       "                                    'history_text'),\n",
       "                                   ('MinMaxScaler', MinMaxScaler(),\n",
       "                                    ['intelligence_score', 'strength_score',\n",
       "                                     'speed_score', 'durability_score',\n",
       "                                     'power_score', 'combat_score'])])),\n",
       "  ('Selection', SelectPercentile(percentile=90)),\n",
       "  ('clf', LogisticRegression(C=0.1, random_state=1))],\n",
       " 'verbose': False,\n",
       " 'preprocessing': ColumnTransformer(transformers=[('bow',\n",
       "                                  CountVectorizer(ngram_range=(1, 2),\n",
       "                                                  tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       "                                  'history_text'),\n",
       "                                 ('MinMaxScaler', MinMaxScaler(),\n",
       "                                  ['intelligence_score', 'strength_score',\n",
       "                                   'speed_score', 'durability_score',\n",
       "                                   'power_score', 'combat_score'])]),\n",
       " 'Selection': SelectPercentile(percentile=90),\n",
       " 'clf': LogisticRegression(C=0.1, random_state=1),\n",
       " 'preprocessing__n_jobs': None,\n",
       " 'preprocessing__remainder': 'drop',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('bow',\n",
       "   CountVectorizer(ngram_range=(1, 2),\n",
       "                   tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       "   'history_text'),\n",
       "  ('MinMaxScaler',\n",
       "   MinMaxScaler(),\n",
       "   ['intelligence_score',\n",
       "    'strength_score',\n",
       "    'speed_score',\n",
       "    'durability_score',\n",
       "    'power_score',\n",
       "    'combat_score'])],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__verbose_feature_names_out': True,\n",
       " 'preprocessing__bow': CountVectorizer(ngram_range=(1, 2),\n",
       "                 tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       " 'preprocessing__MinMaxScaler': MinMaxScaler(),\n",
       " 'preprocessing__bow__analyzer': 'word',\n",
       " 'preprocessing__bow__binary': False,\n",
       " 'preprocessing__bow__decode_error': 'strict',\n",
       " 'preprocessing__bow__dtype': numpy.int64,\n",
       " 'preprocessing__bow__encoding': 'utf-8',\n",
       " 'preprocessing__bow__input': 'content',\n",
       " 'preprocessing__bow__lowercase': True,\n",
       " 'preprocessing__bow__max_df': 1.0,\n",
       " 'preprocessing__bow__max_features': None,\n",
       " 'preprocessing__bow__min_df': 1,\n",
       " 'preprocessing__bow__ngram_range': (1, 2),\n",
       " 'preprocessing__bow__preprocessor': None,\n",
       " 'preprocessing__bow__stop_words': None,\n",
       " 'preprocessing__bow__strip_accents': None,\n",
       " 'preprocessing__bow__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'preprocessing__bow__tokenizer': <__main__.StemmerTokenizer at 0x1ee137904c0>,\n",
       " 'preprocessing__bow__vocabulary': None,\n",
       " 'preprocessing__MinMaxScaler__clip': False,\n",
       " 'preprocessing__MinMaxScaler__copy': True,\n",
       " 'preprocessing__MinMaxScaler__feature_range': (0, 1),\n",
       " 'Selection__percentile': 90,\n",
       " 'Selection__score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n",
       " 'clf__C': 0.1,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__dual': False,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__l1_ratio': None,\n",
       " 'clf__max_iter': 100,\n",
       " 'clf__multi_class': 'auto',\n",
       " 'clf__n_jobs': None,\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': 1,\n",
       " 'clf__solver': 'lbfgs',\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Código aquí ####\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing_transformer),\n",
    "        (\"Selection\", SelectPercentile(f_classif, percentile=90)),\n",
    "        (\"clf\", LogisticRegression(random_state=1,C=0.1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "\n",
    "param_grid = [\n",
    "              \n",
    "       # clasificador 1 + hiperparámetros\n",
    "        {\n",
    "          'Selection__percentile': [20, 40, 60, 80],\n",
    "          #'Selection__score_func': [f_classif, mutual_info_classif],\n",
    "          'preprocessing__bow__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "          #'preprocessing__bow__max_df': [0.5, 0.6],\n",
    "          'preprocessing__bow__min_df': [0.05, 0.1],\n",
    "          'clf': [DecisionTreeClassifier(random_state=50)],\n",
    "          'clf__criterion': [\"gini\", \"entropy\"],\n",
    "        },\n",
    "    \n",
    "        # clasificador 2 + hiperparámetros\n",
    "        {\n",
    "          'Selection__percentile': [20, 40, 60, 80],\n",
    "          #'Selection__score_func': [f_classif, mutual_info_classif],\n",
    "          'preprocessing__bow__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "          #'preprocessing__bow__max_df': [0.5, 0.6],\n",
    "          'preprocessing__bow__min_df': [0.05, 0.1],\n",
    "          'clf':[LogisticRegression(random_state=50)],\n",
    "          'clf__C': [0.01,1000],\n",
    "        },\n",
    "        \n",
    "        # clasificador 3 + hiperparámetros\n",
    "        {\n",
    "          'Selection__percentile': [20, 40, 60, 80],\n",
    "          #'Selection__score_func': [f_classif, mutual_info_classif],\n",
    "          'preprocessing__bow__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "          #'preprocessing__bow__max_df': [0.5, 0.6],\n",
    "          'preprocessing__bow__min_df': [0.05, 0.1],\n",
    "          'clf': [RandomForestClassifier(random_state=50)],\n",
    "          'clf__n_estimators': [100,1000],\n",
    "        },\n",
    "             \n",
    "      \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Halving Grid Search\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "hgs = HalvingGridSearchCV(pipe, param_grid, verbose=10, scoring='f1_macro') #n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 30\n",
      "max_resources_: 860\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 144\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 1/5; 1/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 1/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 1/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 1/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 1/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 1/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 1/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.133) total time=   0.5s\n",
      "[CV 5/5; 1/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 1/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 2/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 2/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.3s\n",
      "[CV 2/5; 2/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 2/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 2/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 2/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 2/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 2/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 2/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 3/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 3/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 3/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 3/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 3/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.333) total time=   0.2s\n",
      "[CV 4/5; 3/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 3/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 3/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 3/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 4/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 4/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.4s\n",
      "[CV 2/5; 4/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 4/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 4/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 4/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 4/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 4/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.133) total time=   0.6s\n",
      "[CV 5/5; 4/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 4/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 1/5; 5/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 5/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.489) total time=   0.3s\n",
      "[CV 2/5; 5/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 5/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 5/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 5/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 5/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 5/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.133) total time=   0.5s\n",
      "[CV 5/5; 5/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 5/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 1/5; 6/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 6/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.267) total time=   0.3s\n",
      "[CV 2/5; 6/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 6/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 6/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 6/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 6/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 6/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.356) total time=   0.5s\n",
      "[CV 5/5; 6/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 6/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 1/5; 7/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 7/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 2/5; 7/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 7/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 7/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.556) total time=   0.2s\n",
      "[CV 4/5; 7/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 7/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 7/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 7/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 1/5; 8/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 8/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 2/5; 8/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 8/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 8/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 8/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 8/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 8/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 8/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 1/5; 9/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 9/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 2/5; 9/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 9/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 9/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 9/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 9/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 9/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 9/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 10/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 10/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 10/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 10/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 10/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 10/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.508) total time=   0.2s\n",
      "[CV 4/5; 10/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 10/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 10/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 10/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   0.2s\n",
      "[CV 1/5; 11/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 11/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 11/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 11/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 11/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 11/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 11/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 11/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 11/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 11/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 12/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 12/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 2/5; 12/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 12/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 12/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 12/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 12/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 12/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 12/144] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 12/144] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 1/5; 13/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 13/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 13/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 13/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 13/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 13/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 13/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 13/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 13/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 13/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 1/5; 14/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 14/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 14/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 14/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 14/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 14/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 4/5; 14/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 14/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 14/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 14/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 1/5; 15/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 15/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.389) total time=   0.3s\n",
      "[CV 2/5; 15/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 15/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 15/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 15/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 15/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 15/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 15/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 15/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 16/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 16/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 16/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 16/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 16/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 16/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 4/5; 16/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 16/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 16/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 16/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 17/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 17/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 17/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 17/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 17/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 17/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 17/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 17/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 17/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 17/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 18/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 18/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 18/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 18/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 18/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 18/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 18/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 18/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 18/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 18/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 19/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 19/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 19/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 19/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 19/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 19/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 19/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 19/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 19/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 1/5; 20/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 20/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 20/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 20/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 20/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 20/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.296) total time=   0.2s\n",
      "[CV 4/5; 20/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 20/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 20/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 20/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 21/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 21/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 21/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 21/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 21/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 21/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 21/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 21/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 21/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 22/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 22/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 22/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 22/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 22/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 22/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.508) total time=   0.2s\n",
      "[CV 4/5; 22/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 22/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 22/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 22/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 1/5; 23/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 23/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 23/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 23/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 23/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 23/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 23/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 23/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 23/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 23/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 24/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 24/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 24/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 24/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 24/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 24/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 24/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 24/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.6s\n",
      "[CV 5/5; 24/144] START Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 24/144] END Selection__percentile=40, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 25/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 25/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   0.3s\n",
      "[CV 2/5; 25/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 25/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 25/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 25/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.625) total time=   0.2s\n",
      "[CV 4/5; 25/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 25/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 25/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 25/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 1/5; 26/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 26/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.3s\n",
      "[CV 2/5; 26/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 26/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 26/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 26/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 26/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 26/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 26/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 26/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 27/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 27/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 27/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 27/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 27/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 27/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 27/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 27/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 27/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 27/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 28/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 28/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 28/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 28/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 28/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 28/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 28/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 28/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 28/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 28/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   0.2s\n",
      "[CV 1/5; 29/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 29/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.3s\n",
      "[CV 2/5; 29/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 29/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.1s\n",
      "[CV 3/5; 29/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 29/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 29/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 29/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.5s\n",
      "[CV 5/5; 29/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 29/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 30/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 30/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 30/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 30/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 30/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 30/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 30/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 30/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.6s\n",
      "[CV 5/5; 30/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 30/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 31/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 31/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 31/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 31/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 31/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 31/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 4/5; 31/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 31/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 31/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 31/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 1/5; 32/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 32/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 32/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 32/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 32/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 32/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 4/5; 32/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 32/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 32/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 32/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 33/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 33/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 33/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 33/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 33/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 33/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 33/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 33/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 33/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 33/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 34/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 34/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 2/5; 34/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 34/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 34/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 34/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 4/5; 34/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 34/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 34/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 34/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 1/5; 35/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 35/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 35/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 35/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 35/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 35/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 35/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 35/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.5s\n",
      "[CV 5/5; 35/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 35/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 36/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 36/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 36/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 36/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 36/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 36/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 4/5; 36/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 36/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.6s\n",
      "[CV 5/5; 36/144] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 36/144] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 37/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 37/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 37/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 37/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 37/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 37/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 4/5; 37/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 37/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 37/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 37/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 1/5; 38/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 38/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 38/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 38/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 38/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 38/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 38/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 38/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.6s\n",
      "[CV 5/5; 38/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 38/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 39/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 39/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 39/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 39/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 39/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 39/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 39/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 39/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 39/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 39/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 40/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 40/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 40/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 40/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 40/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 40/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 40/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 40/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 40/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 40/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 1/5; 41/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 41/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.3s\n",
      "[CV 2/5; 41/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 41/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 41/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 41/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 41/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 41/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 41/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 41/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 42/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 42/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.656) total time=   0.3s\n",
      "[CV 2/5; 42/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 42/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 42/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 42/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 42/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 42/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 42/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 42/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 43/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 43/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 43/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 43/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 43/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 43/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 4/5; 43/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 43/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.5s\n",
      "[CV 5/5; 43/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 43/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 1/5; 44/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 44/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.3s\n",
      "[CV 2/5; 44/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 44/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 44/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 44/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 4/5; 44/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 44/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 44/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 44/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 45/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 45/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 45/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 45/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 45/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 45/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 4/5; 45/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 45/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 45/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 45/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 46/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 46/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 2/5; 46/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 46/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 46/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 46/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 4/5; 46/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 46/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 46/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 46/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 1/5; 47/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 47/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.722) total time=   0.3s\n",
      "[CV 2/5; 47/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 47/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 47/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 47/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.2s\n",
      "[CV 4/5; 47/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 47/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.5s\n",
      "[CV 5/5; 47/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 47/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 48/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 48/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 2/5; 48/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 48/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 48/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 48/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 4/5; 48/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 48/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 48/144] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 48/144] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 1/5; 49/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 49/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 49/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 49/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.782, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 49/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 49/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.625, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 49/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 49/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.700, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 49/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 49/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.711, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 50/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 50/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 50/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 50/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 50/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 50/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.625, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 50/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 50/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.811, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 50/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 50/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.711, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 51/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 51/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 51/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 51/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 51/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 51/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.625, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 51/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 51/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.811, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 51/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 51/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.711, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 52/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 52/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.770, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 52/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 52/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.778, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 52/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 52/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.563, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 52/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 52/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.647, test=0.095) total time=   0.5s\n",
      "[CV 5/5; 52/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 52/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.480, test=0.472) total time=   0.2s\n",
      "[CV 1/5; 53/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 53/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.727, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 53/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 53/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.778, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 53/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 53/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.563, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 53/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 53/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.647, test=0.095) total time=   0.5s\n",
      "[CV 5/5; 53/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 53/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.480, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 54/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 54/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.727, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 54/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 54/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.782, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 54/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 54/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.563, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 54/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 54/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.647, test=0.095) total time=   0.6s\n",
      "[CV 5/5; 54/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 54/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.480, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 55/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 55/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 55/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 55/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.1s\n",
      "[CV 3/5; 55/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 55/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.296) total time=   0.2s\n",
      "[CV 4/5; 55/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 55/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 55/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 55/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 1/5; 56/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 56/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 56/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 3/5; 56/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 56/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 56/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 56/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 56/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 56/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 57/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 57/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 57/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 57/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 3/5; 57/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 57/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 57/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 57/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.278) total time=   0.6s\n",
      "[CV 5/5; 57/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 57/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 58/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 58/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 2/5; 58/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 58/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 3/5; 58/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 58/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 58/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 58/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 58/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 58/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.244) total time=   0.2s\n",
      "[CV 1/5; 59/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 59/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 2/5; 59/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 59/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.095) total time=   0.1s\n",
      "[CV 3/5; 59/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 59/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 59/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 59/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 59/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 59/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 1/5; 60/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 60/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.000) total time=   0.3s\n",
      "[CV 2/5; 60/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 60/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.095) total time=   0.2s\n",
      "[CV 3/5; 60/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 60/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 60/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 60/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.278) total time=   0.6s\n",
      "[CV 5/5; 60/144] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 60/144] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 1/5; 61/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 61/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 61/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 61/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 61/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 61/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.625, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 61/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 61/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.811, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 61/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 61/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.711, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 62/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 62/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 62/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 62/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 62/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 62/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.625, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 62/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 62/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.811, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 62/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 62/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.711, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 63/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 63/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 63/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 63/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 63/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 63/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.625, test=0.400) total time=   0.2s\n",
      "[CV 4/5; 63/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 63/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.811, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 63/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 63/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.711, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 64/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 64/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.727, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 64/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 64/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 64/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 64/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.625, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 64/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 64/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.746, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 64/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 64/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.480, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 65/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 65/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.770, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 65/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 65/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 65/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 65/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.625, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 65/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 65/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.811, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 65/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 65/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.480, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 66/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 66/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.770, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 66/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 66/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 66/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 66/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.625, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 66/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 66/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.746, test=0.095) total time=   0.6s\n",
      "[CV 5/5; 66/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 66/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.480, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 67/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 67/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 67/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 67/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.1s\n",
      "[CV 3/5; 67/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 67/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 67/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 67/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 67/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 67/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 1/5; 68/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 68/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 68/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 68/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.267) total time=   0.2s\n",
      "[CV 3/5; 68/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 68/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 68/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 68/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 68/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 68/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.244) total time=   0.3s\n",
      "[CV 1/5; 69/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 69/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 69/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 69/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.267) total time=   0.2s\n",
      "[CV 3/5; 69/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 69/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 69/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 69/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.278) total time=   0.5s\n",
      "[CV 5/5; 69/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 69/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 1/5; 70/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 70/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.095) total time=   0.3s\n",
      "[CV 2/5; 70/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 70/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.1s\n",
      "[CV 3/5; 70/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 70/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 70/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 70/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 70/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 70/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 1/5; 71/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 71/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 71/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 71/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.267) total time=   0.1s\n",
      "[CV 3/5; 71/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 71/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 71/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 71/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.5s\n",
      "[CV 5/5; 71/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 71/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.489) total time=   0.3s\n",
      "[CV 1/5; 72/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 72/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 72/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 72/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.267) total time=   0.2s\n",
      "[CV 3/5; 72/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 72/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 72/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 72/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 72/144] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 72/144] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.489) total time=   0.3s\n",
      "[CV 1/5; 73/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 73/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 73/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 73/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 73/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 73/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.595, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 73/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 73/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.811, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 73/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 73/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 74/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 74/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 74/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 74/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 74/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 74/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.595, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 74/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 74/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.914, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 74/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 74/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 75/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 75/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.809, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 75/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 75/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 75/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 75/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.595, test=0.190) total time=   0.2s\n",
      "[CV 4/5; 75/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 75/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.914, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 75/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 75/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.782, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 76/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 76/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.770, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 76/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 76/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 76/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 76/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.563, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 76/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 76/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.811, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 76/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 76/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.748, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 77/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 77/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.770, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 77/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 77/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 77/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 77/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.595, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 77/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 77/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.866, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 77/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 77/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.782, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 78/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 78/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.770, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 78/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 78/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 78/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 78/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.595, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 78/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 78/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.866, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 78/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 78/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.782, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 79/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 79/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 79/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 79/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.267) total time=   0.1s\n",
      "[CV 3/5; 79/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 79/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 79/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 79/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 79/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 79/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 80/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 80/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 80/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 80/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.267) total time=   0.2s\n",
      "[CV 3/5; 80/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 80/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 80/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 80/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 80/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 80/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 81/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 81/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 81/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 81/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.267) total time=   0.2s\n",
      "[CV 3/5; 81/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 81/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 81/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 81/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.6s\n",
      "[CV 5/5; 81/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 81/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.489) total time=   0.3s\n",
      "[CV 1/5; 82/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 82/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 2/5; 82/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 82/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.190) total time=   0.1s\n",
      "[CV 3/5; 82/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 82/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 82/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 82/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 82/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 82/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 83/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 83/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 83/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 83/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.1s\n",
      "[CV 3/5; 83/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 83/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 83/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 83/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 83/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 83/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 84/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 84/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 84/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 84/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 3/5; 84/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 84/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.2s\n",
      "[CV 4/5; 84/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 84/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 84/144] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 84/144] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 85/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 85/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.844, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 85/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 85/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 85/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 85/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.654, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 85/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 85/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.914, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 85/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 85/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 86/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 86/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.844, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 86/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 86/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 86/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 86/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.654, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 86/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 86/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.914, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 86/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 86/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 87/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 87/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.844, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 87/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 87/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 87/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 87/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.654, test=0.111) total time=   0.2s\n",
      "[CV 4/5; 87/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 87/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.914, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 87/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 87/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 88/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 88/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.770, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 88/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 88/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 88/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 88/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.595, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 88/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 88/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.914, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 88/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 88/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 89/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 89/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.809, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 89/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 89/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.167) total time=   0.1s\n",
      "[CV 3/5; 89/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 89/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.595, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 89/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 89/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.914, test=0.167) total time=   0.5s\n",
      "[CV 5/5; 89/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 89/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 90/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 90/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.809, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 90/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 90/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 90/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 90/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.595, test=0.222) total time=   0.2s\n",
      "[CV 4/5; 90/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 90/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.914, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 90/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 90/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.815, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 91/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 91/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 2/5; 91/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 91/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 3/5; 91/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 91/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.133) total time=   0.2s\n",
      "[CV 4/5; 91/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 91/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   0.5s\n",
      "[CV 5/5; 91/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 91/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 92/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 92/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 92/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 92/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 3/5; 92/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 92/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.133) total time=   0.2s\n",
      "[CV 4/5; 92/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 92/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.5s\n",
      "[CV 5/5; 92/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 92/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 93/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 93/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 2/5; 93/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 93/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 3/5; 93/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 93/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.133) total time=   0.2s\n",
      "[CV 4/5; 93/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 93/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.389) total time=   0.6s\n",
      "[CV 5/5; 93/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 93/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 94/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 94/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 2/5; 94/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 94/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   0.1s\n",
      "[CV 3/5; 94/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 94/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 94/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 94/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.413) total time=   0.5s\n",
      "[CV 5/5; 94/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 94/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 95/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 95/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 2/5; 95/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 95/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 3/5; 95/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 95/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 95/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 95/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 5/5; 95/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 95/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 96/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 96/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.356) total time=   0.3s\n",
      "[CV 2/5; 96/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 96/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.533) total time=   0.2s\n",
      "[CV 3/5; 96/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 96/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.286) total time=   0.2s\n",
      "[CV 4/5; 96/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 96/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.6s\n",
      "[CV 5/5; 96/144] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 96/144] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 97/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 97/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 97/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 97/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 97/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 97/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 97/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 97/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 97/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 97/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 98/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 98/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 98/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 98/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 98/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 98/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 98/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 98/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 98/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 98/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.4s\n",
      "[CV 1/5; 99/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 99/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 99/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 99/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 99/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 99/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 99/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 99/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 99/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 99/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.4s\n",
      "[CV 1/5; 100/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 100/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 100/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 100/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 100/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 100/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 100/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 100/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   0.6s\n",
      "[CV 5/5; 100/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 100/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 1/5; 101/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 101/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 101/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 101/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 101/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 101/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 4/5; 101/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 101/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 101/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 101/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 102/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 102/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 102/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 102/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 102/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 102/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 4/5; 102/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 102/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 102/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 102/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.4s\n",
      "[CV 1/5; 103/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 103/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 103/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 103/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 103/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 103/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 103/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 103/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 103/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 103/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 104/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 104/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 104/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 104/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 104/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 104/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 104/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 104/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 5/5; 104/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 104/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 105/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 105/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 105/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 105/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 105/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 105/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 105/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 105/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 105/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 105/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 106/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 106/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 106/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 106/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.0s\n",
      "[CV 3/5; 106/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 106/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   1.1s\n",
      "[CV 4/5; 106/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 106/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.111) total time=   1.4s\n",
      "[CV 5/5; 106/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 106/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.357) total time=   1.2s\n",
      "[CV 1/5; 107/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 107/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 107/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 107/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.0s\n",
      "[CV 3/5; 107/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 107/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.1s\n",
      "[CV 4/5; 107/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 107/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 5/5; 107/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 107/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   1.2s\n",
      "[CV 1/5; 108/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 108/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 108/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 108/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 108/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 108/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.1s\n",
      "[CV 4/5; 108/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 108/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   1.5s\n",
      "[CV 5/5; 108/144] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 108/144] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   1.2s\n",
      "[CV 1/5; 109/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 109/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 109/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 109/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 109/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 109/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 109/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 109/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 109/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 109/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 110/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 110/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 110/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 110/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 3/5; 110/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 110/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 110/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 110/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 110/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 110/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   0.4s\n",
      "[CV 1/5; 111/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 111/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 111/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 111/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 111/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 111/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 4/5; 111/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 111/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 5/5; 111/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 111/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.472) total time=   0.4s\n",
      "[CV 1/5; 112/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 112/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 112/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 112/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 112/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 112/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 112/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 112/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 112/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 112/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 113/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 113/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 113/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 113/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 113/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 113/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 113/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 113/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 113/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 113/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.357) total time=   0.3s\n",
      "[CV 1/5; 114/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 114/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 114/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 114/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 3/5; 114/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 114/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 4/5; 114/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 114/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 114/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 114/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.357) total time=   0.4s\n",
      "[CV 1/5; 115/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 115/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 115/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 115/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 115/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 115/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 115/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 115/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 5/5; 115/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 115/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   1.2s\n",
      "[CV 1/5; 116/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 116/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 2/5; 116/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 116/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 116/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 116/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.1s\n",
      "[CV 4/5; 116/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 116/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 116/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 116/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   1.2s\n",
      "[CV 1/5; 117/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 117/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 2/5; 117/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 117/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 117/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 117/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 117/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 117/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 117/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 117/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.472) total time=   1.3s\n",
      "[CV 1/5; 118/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 118/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 2/5; 118/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 118/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 118/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 118/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 118/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 118/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 5/5; 118/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 118/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   1.2s\n",
      "[CV 1/5; 119/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 119/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 119/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 119/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 119/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 119/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 119/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 119/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 119/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 119/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   1.2s\n",
      "[CV 1/5; 120/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 120/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 120/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 120/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 120/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 120/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 120/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 120/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 120/144] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 120/144] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.472) total time=   1.2s\n",
      "[CV 1/5; 121/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 121/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 121/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 121/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 121/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 121/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 121/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 121/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 121/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 121/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.452) total time=   0.3s\n",
      "[CV 1/5; 122/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 122/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 122/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 122/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 122/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 122/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 122/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 122/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 122/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 122/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.472) total time=   0.4s\n",
      "[CV 1/5; 123/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 123/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 123/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 123/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 3/5; 123/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 123/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 123/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 123/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 5/5; 123/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 123/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 1/5; 124/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 124/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 2/5; 124/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 124/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 3/5; 124/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 124/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 4/5; 124/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 124/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 124/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 124/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 1/5; 125/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 125/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 125/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 125/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 125/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 125/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 125/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 125/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.6s\n",
      "[CV 5/5; 125/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 125/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 126/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 126/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 126/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 126/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.3s\n",
      "[CV 3/5; 126/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 126/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.250) total time=   0.3s\n",
      "[CV 4/5; 126/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 126/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 126/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 126/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.452) total time=   0.4s\n",
      "[CV 1/5; 127/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 127/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 127/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 127/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 127/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 127/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 127/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 127/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.4s\n",
      "[CV 5/5; 127/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 127/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 128/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 128/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 128/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 128/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 128/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 128/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   1.2s\n",
      "[CV 4/5; 128/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 128/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 128/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 128/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 129/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 129/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 2/5; 129/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 129/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 129/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 129/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 129/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 129/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 129/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 129/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 130/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 130/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 130/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 130/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 130/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 130/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 130/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 130/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.190) total time=   1.4s\n",
      "[CV 5/5; 130/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 130/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   1.3s\n",
      "[CV 1/5; 131/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 131/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 131/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 131/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 131/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 131/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 131/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 131/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 131/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 131/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.452) total time=   1.2s\n",
      "[CV 1/5; 132/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 132/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 2/5; 132/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 132/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 132/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 132/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   1.2s\n",
      "[CV 4/5; 132/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 132/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 132/144] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 132/144] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.452) total time=   1.3s\n",
      "[CV 1/5; 133/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 133/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 133/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 133/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 133/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 133/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   0.3s\n",
      "[CV 4/5; 133/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 133/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 133/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 133/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   0.3s\n",
      "[CV 1/5; 134/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 134/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 134/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 134/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 134/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 134/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 4/5; 134/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 134/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 134/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 134/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.3s\n",
      "[CV 1/5; 135/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 135/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 135/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 135/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.389) total time=   0.2s\n",
      "[CV 3/5; 135/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 135/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.286) total time=   0.3s\n",
      "[CV 4/5; 135/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 135/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 135/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 135/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   0.4s\n",
      "[CV 1/5; 136/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 136/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 136/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 136/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 136/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 136/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.250) total time=   0.3s\n",
      "[CV 4/5; 136/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 136/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 136/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 136/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.489) total time=   0.3s\n",
      "[CV 1/5; 137/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 137/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 137/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 137/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.2s\n",
      "[CV 3/5; 137/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 137/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   0.3s\n",
      "[CV 4/5; 137/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 137/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   0.6s\n",
      "[CV 5/5; 137/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 137/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.250) total time=   0.3s\n",
      "[CV 1/5; 138/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 138/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.4s\n",
      "[CV 2/5; 138/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 138/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   0.2s\n",
      "[CV 3/5; 138/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 138/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   0.3s\n",
      "[CV 4/5; 138/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 138/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   0.7s\n",
      "[CV 5/5; 138/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 138/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.619) total time=   0.4s\n",
      "[CV 1/5; 139/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 139/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 139/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 139/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 139/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 139/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 139/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 139/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 139/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 139/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 140/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 140/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 140/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 140/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.190) total time=   1.1s\n",
      "[CV 3/5; 140/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 140/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.400) total time=   1.1s\n",
      "[CV 4/5; 140/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 140/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 140/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 140/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.3s\n",
      "[CV 1/5; 141/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 141/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 141/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0 0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 141/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.190) total time=   1.1s\n",
      "[CV 3/5; 141/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 141/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.296) total time=   1.1s\n",
      "[CV 4/5; 141/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 141/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 141/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 141/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 142/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 142/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 142/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 142/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 142/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 142/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 4/5; 142/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 142/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.167) total time=   1.6s\n",
      "[CV 5/5; 142/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 142/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.472) total time=   1.2s\n",
      "[CV 1/5; 143/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 143/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.3s\n",
      "[CV 2/5; 143/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 143/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 143/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 143/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.296) total time=   1.1s\n",
      "[CV 4/5; 143/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 143/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 143/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 143/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "[CV 1/5; 144/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 144/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.2s\n",
      "[CV 2/5; 144/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 144/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.1s\n",
      "[CV 3/5; 144/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 144/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.296) total time=   1.1s\n",
      "[CV 4/5; 144/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 144/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.167) total time=   1.5s\n",
      "[CV 5/5; 144/144] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 144/144] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.2s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 48\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5; 1/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 1/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.246) total time=   1.2s\n",
      "[CV 2/5; 1/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.323) total time=   1.1s\n",
      "[CV 3/5; 1/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 1/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.717) total time=   0.8s\n",
      "[CV 4/5; 1/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.257) total time=   0.8s\n",
      "[CV 5/5; 1/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 1/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.231) total time=   1.0s\n",
      "[CV 1/5; 2/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 2/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.444) total time=   1.1s\n",
      "[CV 2/5; 2/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 2/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.326) total time=   1.0s\n",
      "[CV 3/5; 2/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 2/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.323) total time=   0.7s\n",
      "[CV 4/5; 2/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 2/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.293) total time=   0.7s\n",
      "[CV 5/5; 2/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 2/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.314) total time=   0.9s\n",
      "[CV 1/5; 3/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 3/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.353) total time=   1.2s\n",
      "[CV 2/5; 3/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 3/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.342) total time=   1.1s\n",
      "[CV 3/5; 3/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 3/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.428) total time=   0.8s\n",
      "[CV 4/5; 3/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 3/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.610) total time=   0.9s\n",
      "[CV 5/5; 3/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 3/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.238) total time=   1.1s\n",
      "[CV 1/5; 4/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 4/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.246) total time=   1.2s\n",
      "[CV 2/5; 4/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.324) total time=   1.1s\n",
      "[CV 3/5; 4/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 4/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.364) total time=   0.8s\n",
      "[CV 4/5; 4/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.532) total time=   0.8s\n",
      "[CV 5/5; 4/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 4/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.462) total time=   1.0s\n",
      "[CV 1/5; 5/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 5/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.270) total time=   1.2s\n",
      "[CV 2/5; 5/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 5/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   1.2s\n",
      "[CV 3/5; 5/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 5/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.371) total time=   0.8s\n",
      "[CV 4/5; 5/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 5/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 5/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 5/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.267) total time=   1.0s\n",
      "[CV 1/5; 6/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 6/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.333) total time=   1.4s\n",
      "[CV 2/5; 6/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 6/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.423) total time=   1.2s\n",
      "[CV 3/5; 6/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 6/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.400) total time=   0.9s\n",
      "[CV 4/5; 6/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 6/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.9s\n",
      "[CV 5/5; 6/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 6/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.267) total time=   1.1s\n",
      "[CV 1/5; 7/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 7/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.273) total time=   2.3s\n",
      "[CV 2/5; 7/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 7/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.253) total time=   2.1s\n",
      "[CV 3/5; 7/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 7/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.430) total time=   1.8s\n",
      "[CV 4/5; 7/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 7/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.8s\n",
      "[CV 5/5; 7/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 7/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.267) total time=   2.0s\n",
      "[CV 1/5; 8/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 8/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.825, test=0.270) total time=   1.1s\n",
      "[CV 2/5; 8/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 8/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.458, test=0.253) total time=   1.0s\n",
      "[CV 3/5; 8/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 8/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.549, test=0.521) total time=   0.7s\n",
      "[CV 4/5; 8/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 8/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.581, test=0.542) total time=   0.7s\n",
      "[CV 5/5; 8/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 8/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.564, test=0.267) total time=   0.9s\n",
      "[CV 1/5; 9/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 9/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.273) total time=   2.1s\n",
      "[CV 2/5; 9/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 9/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.238) total time=   2.0s\n",
      "[CV 3/5; 9/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 9/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.463) total time=   1.8s\n",
      "[CV 4/5; 9/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 9/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.7s\n",
      "[CV 5/5; 9/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 9/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   2.0s\n",
      "[CV 1/5; 10/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 10/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.273) total time=   1.2s\n",
      "[CV 2/5; 10/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 10/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.423) total time=   1.1s\n",
      "[CV 3/5; 10/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 10/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.371) total time=   0.8s\n",
      "[CV 4/5; 10/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 10/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.411) total time=   0.9s\n",
      "[CV 5/5; 10/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 10/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   1.0s\n",
      "[CV 1/5; 11/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 11/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.864, test=0.273) total time=   1.2s\n",
      "[CV 2/5; 11/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.550, test=0.253) total time=   1.2s\n",
      "[CV 3/5; 11/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 11/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.681, test=0.476) total time=   0.8s\n",
      "[CV 4/5; 11/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 11/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.646, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 11/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 11/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.587, test=0.267) total time=   1.1s\n",
      "[CV 1/5; 12/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 12/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.845, test=0.270) total time=   1.3s\n",
      "[CV 2/5; 12/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 12/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.458, test=0.253) total time=   1.2s\n",
      "[CV 3/5; 12/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 12/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.577, test=0.521) total time=   0.9s\n",
      "[CV 4/5; 12/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 12/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.613, test=0.542) total time=   0.9s\n",
      "[CV 5/5; 12/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 12/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.564, test=0.267) total time=   1.1s\n",
      "[CV 1/5; 13/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 13/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.306) total time=   2.2s\n",
      "[CV 2/5; 13/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 13/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.342) total time=   2.0s\n",
      "[CV 3/5; 13/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 13/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.430) total time=   1.8s\n",
      "[CV 4/5; 13/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 13/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   1.8s\n",
      "[CV 5/5; 13/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 13/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.253) total time=   1.9s\n",
      "[CV 1/5; 14/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 14/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.218) total time=   2.2s\n",
      "[CV 2/5; 14/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 14/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.342) total time=   2.4s\n",
      "[CV 3/5; 14/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 14/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.430) total time=   1.8s\n",
      "[CV 4/5; 14/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 14/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   1.7s\n",
      "[CV 5/5; 14/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 14/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.253) total time=   2.0s\n",
      "[CV 1/5; 15/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 15/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.194) total time=   1.1s\n",
      "[CV 2/5; 15/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 15/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.462) total time=   1.0s\n",
      "[CV 3/5; 15/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 15/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.460) total time=   0.8s\n",
      "[CV 4/5; 15/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 15/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.411) total time=   0.8s\n",
      "[CV 5/5; 15/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 15/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.267) total time=   1.0s\n",
      "[CV 1/5; 16/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 16/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.864, test=0.273) total time=   1.2s\n",
      "[CV 2/5; 16/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 16/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.550, test=0.253) total time=   1.1s\n",
      "[CV 3/5; 16/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 16/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.681, test=0.476) total time=   0.8s\n",
      "[CV 4/5; 16/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 16/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.646, test=0.500) total time=   0.9s\n",
      "[CV 5/5; 16/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 16/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.587, test=0.267) total time=   1.0s\n",
      "[CV 1/5; 17/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 17/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.270) total time=   1.2s\n",
      "[CV 2/5; 17/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 17/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.462) total time=   1.1s\n",
      "[CV 3/5; 17/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 17/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.463) total time=   0.9s\n",
      "[CV 4/5; 17/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 17/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.458) total time=   0.8s\n",
      "[CV 5/5; 17/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 17/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.267) total time=   1.0s\n",
      "[CV 1/5; 18/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 18/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.845, test=0.270) total time=   1.2s\n",
      "[CV 2/5; 18/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 18/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.458, test=0.253) total time=   1.1s\n",
      "[CV 3/5; 18/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 18/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.577, test=0.521) total time=   0.8s\n",
      "[CV 4/5; 18/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 18/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.613, test=0.542) total time=   0.8s\n",
      "[CV 5/5; 18/48] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 18/48] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.564, test=0.267) total time=   0.9s\n",
      "[CV 1/5; 19/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 19/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.273) total time=   2.0s\n",
      "[CV 2/5; 19/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 19/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.238) total time=   1.8s\n",
      "[CV 3/5; 19/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 19/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.428) total time=   1.6s\n",
      "[CV 4/5; 19/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 19/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.6s\n",
      "[CV 5/5; 19/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 19/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   1.8s\n",
      "[CV 1/5; 20/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 20/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.885, test=0.299) total time=   1.1s\n",
      "[CV 2/5; 20/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 20/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.396, test=0.238) total time=   1.0s\n",
      "[CV 3/5; 20/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 20/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.656, test=0.387) total time=   0.7s\n",
      "[CV 4/5; 20/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 20/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.559, test=0.500) total time=   0.7s\n",
      "[CV 5/5; 20/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 20/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.564, test=0.267) total time=   0.9s\n",
      "[CV 1/5; 21/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.885, test=0.299) total time=   1.2s\n",
      "[CV 2/5; 21/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 21/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.458, test=0.238) total time=   1.0s\n",
      "[CV 3/5; 21/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 21/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.645, test=0.387) total time=   0.8s\n",
      "[CV 4/5; 21/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 21/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.569, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 21/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 21/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.564, test=0.267) total time=   1.0s\n",
      "[CV 1/5; 22/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 22/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.885, test=0.299) total time=   1.1s\n",
      "[CV 2/5; 22/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 22/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.458, test=0.238) total time=   1.0s\n",
      "[CV 3/5; 22/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 22/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.645, test=0.387) total time=   0.7s\n",
      "[CV 4/5; 22/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 22/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.569, test=0.500) total time=   0.7s\n",
      "[CV 5/5; 22/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 22/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.564, test=0.267) total time=   0.9s\n",
      "[CV 1/5; 23/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 23/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.273) total time=   1.2s\n",
      "[CV 2/5; 23/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 23/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.342) total time=   1.1s\n",
      "[CV 3/5; 23/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 23/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.463) total time=   0.8s\n",
      "[CV 4/5; 23/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 23/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 23/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 23/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.238) total time=   1.0s\n",
      "[CV 1/5; 24/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 24/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.218) total time=   2.0s\n",
      "[CV 2/5; 24/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 24/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.342) total time=   1.8s\n",
      "[CV 3/5; 24/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 24/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.315) total time=   1.6s\n",
      "[CV 4/5; 24/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 24/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   1.6s\n",
      "[CV 5/5; 24/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 24/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   1.8s\n",
      "[CV 1/5; 25/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 25/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.208) total time=   1.0s\n",
      "[CV 2/5; 25/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 25/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.370) total time=   0.9s\n",
      "[CV 3/5; 25/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 25/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.383) total time=   0.7s\n",
      "[CV 4/5; 25/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 25/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.625) total time=   0.7s\n",
      "[CV 5/5; 25/48] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 25/48] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.269) total time=   0.8s\n",
      "[CV 1/5; 26/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 26/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.159) total time=   1.1s\n",
      "[CV 2/5; 26/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 26/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.309) total time=   1.0s\n",
      "[CV 3/5; 26/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 26/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.399) total time=   0.8s\n",
      "[CV 4/5; 26/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 26/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.390) total time=   0.7s\n",
      "[CV 5/5; 26/48] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 26/48] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.314) total time=   0.9s\n",
      "[CV 1/5; 27/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 27/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.353) total time=   1.3s\n",
      "[CV 2/5; 27/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 27/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.253) total time=   1.1s\n",
      "[CV 3/5; 27/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 27/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.493) total time=   0.8s\n",
      "[CV 4/5; 27/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 27/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 27/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 27/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.253) total time=   1.0s\n",
      "[CV 1/5; 28/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 28/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.989, test=0.370) total time=   1.2s\n",
      "[CV 2/5; 28/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 28/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.342) total time=   1.1s\n",
      "[CV 3/5; 28/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 28/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.258) total time=   0.8s\n",
      "[CV 4/5; 28/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 28/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 28/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 28/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.253) total time=   1.0s\n",
      "[CV 1/5; 29/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 29/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.365) total time=   1.1s\n",
      "[CV 2/5; 29/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 29/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.620) total time=   1.0s\n",
      "[CV 3/5; 29/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 29/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.443) total time=   0.8s\n",
      "[CV 4/5; 29/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 29/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.458) total time=   0.7s\n",
      "[CV 5/5; 29/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 29/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.0s\n",
      "[CV 1/5; 30/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 30/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.989, test=0.297) total time=   1.1s\n",
      "[CV 2/5; 30/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 30/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.342) total time=   1.0s\n",
      "[CV 3/5; 30/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 30/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.315) total time=   0.8s\n",
      "[CV 4/5; 30/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 30/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 5/5; 30/48] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 30/48] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   0.9s\n",
      "[CV 1/5; 31/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 31/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.989, test=0.375) total time=   1.0s\n",
      "[CV 2/5; 31/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 31/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.213) total time=   0.9s\n",
      "[CV 3/5; 31/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 31/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.310) total time=   0.7s\n",
      "[CV 4/5; 31/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 31/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.333) total time=   0.7s\n",
      "[CV 5/5; 31/48] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 31/48] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=entropy, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.293) total time=   0.8s\n",
      "[CV 1/5; 32/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 32/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.273) total time=   1.1s\n",
      "[CV 2/5; 32/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 32/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.462) total time=   1.0s\n",
      "[CV 3/5; 32/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 32/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.432) total time=   0.8s\n",
      "[CV 4/5; 32/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 32/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.542) total time=   0.8s\n",
      "[CV 5/5; 32/48] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 32/48] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.253) total time=   0.9s\n",
      "[CV 1/5; 33/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 33/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.274) total time=   1.2s\n",
      "[CV 2/5; 33/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 33/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.342) total time=   1.1s\n",
      "[CV 3/5; 33/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 33/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.371) total time=   0.8s\n",
      "[CV 4/5; 33/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 33/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 33/48] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 33/48] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.253) total time=   1.0s\n",
      "[CV 1/5; 34/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 34/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.303) total time=   1.2s\n",
      "[CV 2/5; 34/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 34/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.342) total time=   1.1s\n",
      "[CV 3/5; 34/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 34/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.428) total time=   0.8s\n",
      "[CV 4/5; 34/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 34/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 34/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 34/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.253) total time=   1.0s\n",
      "[CV 1/5; 35/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 35/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.246) total time=   1.2s\n",
      "[CV 2/5; 35/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 35/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.356) total time=   1.1s\n",
      "[CV 3/5; 35/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 35/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.364) total time=   0.8s\n",
      "[CV 4/5; 35/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 35/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 35/48] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 35/48] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.462) total time=   1.0s\n",
      "[CV 1/5; 36/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 36/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.203) total time=   1.1s\n",
      "[CV 2/5; 36/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 36/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.373) total time=   1.0s\n",
      "[CV 3/5; 36/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 36/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.396) total time=   0.8s\n",
      "[CV 4/5; 36/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 36/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.8s\n",
      "[CV 5/5; 36/48] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 36/48] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.267) total time=   0.9s\n",
      "[CV 1/5; 37/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 37/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.219) total time=   1.2s\n",
      "[CV 2/5; 37/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 37/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.365) total time=   1.1s\n",
      "[CV 3/5; 37/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 37/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.396) total time=   0.8s\n",
      "[CV 4/5; 37/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 37/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.416) total time=   0.8s\n",
      "[CV 5/5; 37/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 37/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.0s\n",
      "[CV 1/5; 38/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 38/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.218) total time=   1.1s\n",
      "[CV 2/5; 38/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 38/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.365) total time=   1.0s\n",
      "[CV 3/5; 38/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 38/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.396) total time=   0.7s\n",
      "[CV 4/5; 38/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 38/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.458) total time=   0.7s\n",
      "[CV 5/5; 38/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 38/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.205) total time=   0.9s\n",
      "[CV 1/5; 39/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 39/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.302) total time=   1.2s\n",
      "[CV 2/5; 39/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 39/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.388) total time=   1.1s\n",
      "[CV 3/5; 39/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 39/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.315) total time=   0.8s\n",
      "[CV 4/5; 39/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 39/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.532) total time=   0.8s\n",
      "[CV 5/5; 39/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 39/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.238) total time=   1.0s\n",
      "[CV 1/5; 40/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 40/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.302) total time=   1.1s\n",
      "[CV 2/5; 40/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.388) total time=   1.0s\n",
      "[CV 3/5; 40/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 40/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.315) total time=   0.7s\n",
      "[CV 4/5; 40/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 40/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.532) total time=   0.7s\n",
      "[CV 5/5; 40/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 40/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.238) total time=   0.9s\n",
      "[CV 1/5; 41/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 41/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.248) total time=   1.1s\n",
      "[CV 2/5; 41/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 41/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.423) total time=   1.0s\n",
      "[CV 3/5; 41/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 41/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.315) total time=   0.7s\n",
      "[CV 4/5; 41/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 41/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.532) total time=   0.7s\n",
      "[CV 5/5; 41/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 41/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.9s\n",
      "[CV 1/5; 42/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 42/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.248) total time=   1.1s\n",
      "[CV 2/5; 42/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 42/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.296) total time=   1.0s\n",
      "[CV 3/5; 42/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 42/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.365) total time=   0.7s\n",
      "[CV 4/5; 42/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 42/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.416) total time=   0.7s\n",
      "[CV 5/5; 42/48] START Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 42/48] END Selection__percentile=60, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.444) total time=   0.9s\n",
      "[CV 1/5; 43/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 43/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.389) total time=   1.1s\n",
      "[CV 2/5; 43/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 43/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.398) total time=   1.0s\n",
      "[CV 3/5; 43/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 43/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.286) total time=   0.7s\n",
      "[CV 4/5; 43/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 43/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.579) total time=   0.7s\n",
      "[CV 5/5; 43/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 43/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.9s\n",
      "[CV 1/5; 44/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 44/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.389) total time=   1.2s\n",
      "[CV 2/5; 44/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 44/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.398) total time=   1.1s\n",
      "[CV 3/5; 44/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 44/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.256) total time=   0.8s\n",
      "[CV 4/5; 44/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 44/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.532) total time=   0.8s\n",
      "[CV 5/5; 44/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 44/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.0s\n",
      "[CV 1/5; 45/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 45/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.389) total time=   1.1s\n",
      "[CV 2/5; 45/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 45/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.398) total time=   1.0s\n",
      "[CV 3/5; 45/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 45/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.256) total time=   0.7s\n",
      "[CV 4/5; 45/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 45/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.532) total time=   0.8s\n",
      "[CV 5/5; 45/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 45/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   1.0s\n",
      "[CV 1/5; 46/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.367) total time=   1.1s\n",
      "[CV 2/5; 46/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 46/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.306) total time=   1.1s\n",
      "[CV 3/5; 46/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 46/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.273) total time=   0.8s\n",
      "[CV 4/5; 46/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 46/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.458) total time=   0.8s\n",
      "[CV 5/5; 46/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 46/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.222) total time=   0.9s\n",
      "[CV 1/5; 47/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.404) total time=   1.1s\n",
      "[CV 2/5; 47/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 47/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.365) total time=   1.0s\n",
      "[CV 3/5; 47/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 47/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.273) total time=   0.7s\n",
      "[CV 4/5; 47/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 47/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   0.7s\n",
      "[CV 5/5; 47/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 47/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.222) total time=   0.9s\n",
      "[CV 1/5; 48/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 48/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.367) total time=   1.2s\n",
      "[CV 2/5; 48/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 48/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.306) total time=   1.1s\n",
      "[CV 3/5; 48/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 48/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.273) total time=   0.8s\n",
      "[CV 4/5; 48/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 48/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.458) total time=   0.8s\n",
      "[CV 5/5; 48/48] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 48/48] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.222) total time=   1.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 16\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5; 1/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 1/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.421) total time=   3.3s\n",
      "[CV 2/5; 1/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 1/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.449) total time=   3.0s\n",
      "[CV 3/5; 1/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 1/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.376) total time=   3.1s\n",
      "[CV 4/5; 1/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 1/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.415) total time=   2.9s\n",
      "[CV 5/5; 1/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 1/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.373) total time=   3.1s\n",
      "[CV 1/5; 2/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 2/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.312) total time=   3.4s\n",
      "[CV 2/5; 2/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 2/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.498) total time=   3.0s\n",
      "[CV 3/5; 2/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 2/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.421) total time=   3.1s\n",
      "[CV 4/5; 2/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 2/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.392) total time=   2.9s\n",
      "[CV 5/5; 2/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 2/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.295) total time=   3.2s\n",
      "[CV 1/5; 3/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 3/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.491) total time=   4.6s\n",
      "[CV 2/5; 3/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 3/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.471) total time=   4.2s\n",
      "[CV 3/5; 3/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 3/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.438) total time=   4.4s\n",
      "[CV 4/5; 3/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 3/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.438) total time=   4.0s\n",
      "[CV 5/5; 3/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 3/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.424) total time=   4.2s\n",
      "[CV 1/5; 4/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 4/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.626, test=0.247) total time=   3.0s\n",
      "[CV 2/5; 4/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.654, test=0.398) total time=   2.8s\n",
      "[CV 3/5; 4/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 4/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.537, test=0.238) total time=   2.9s\n",
      "[CV 4/5; 4/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 4/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.581, test=0.475) total time=   2.7s\n",
      "[CV 5/5; 4/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 4/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.581, test=0.330) total time=   2.9s\n",
      "[CV 1/5; 5/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 5/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.633, test=0.244) total time=   3.2s\n",
      "[CV 2/5; 5/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.665, test=0.398) total time=   2.9s\n",
      "[CV 3/5; 5/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 5/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.537, test=0.274) total time=   3.1s\n",
      "[CV 4/5; 5/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 5/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.634, test=0.424) total time=   2.9s\n",
      "[CV 5/5; 5/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 5/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.587, test=0.330) total time=   3.0s\n",
      "[CV 1/5; 6/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 6/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.633, test=0.244) total time=   3.4s\n",
      "[CV 2/5; 6/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.665, test=0.398) total time=   3.0s\n",
      "[CV 3/5; 6/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 6/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.544, test=0.238) total time=   3.2s\n",
      "[CV 4/5; 6/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 6/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.638, test=0.408) total time=   3.0s\n",
      "[CV 5/5; 6/16] START Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 6/16] END Selection__percentile=20, clf=LogisticRegression(random_state=50), clf__C=0.01, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.587, test=0.330) total time=   3.1s\n",
      "[CV 1/5; 7/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 7/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.348) total time=   3.5s\n",
      "[CV 2/5; 7/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 7/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.485) total time=   3.2s\n",
      "[CV 3/5; 7/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 7/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.289) total time=   3.3s\n",
      "[CV 4/5; 7/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 7/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.380) total time=   3.1s\n",
      "[CV 5/5; 7/16] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 7/16] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.351) total time=   3.3s\n",
      "[CV 1/5; 8/16] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 8/16] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.536) total time=   3.0s\n",
      "[CV 2/5; 8/16] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 8/16] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.457) total time=   2.7s\n",
      "[CV 3/5; 8/16] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 8/16] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.398) total time=   2.9s\n",
      "[CV 4/5; 8/16] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 8/16] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.431) total time=   2.7s\n",
      "[CV 5/5; 8/16] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 8/16] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.500) total time=   2.8s\n",
      "[CV 1/5; 9/16] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/16] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.481) total time=   3.1s\n",
      "[CV 2/5; 9/16] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/16] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.448) total time=   2.8s\n",
      "[CV 3/5; 9/16] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/16] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.495) total time=   3.0s\n",
      "[CV 4/5; 9/16] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/16] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.383) total time=   2.7s\n",
      "[CV 5/5; 9/16] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/16] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.988, test=0.435) total time=   2.9s\n",
      "[CV 1/5; 10/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 10/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.406) total time=   3.3s\n",
      "[CV 2/5; 10/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 10/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.455) total time=   3.0s\n",
      "[CV 3/5; 10/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 10/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.371) total time=   3.2s\n",
      "[CV 4/5; 10/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 10/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.345) total time=   2.9s\n",
      "[CV 5/5; 10/16] START Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 10/16] END Selection__percentile=60, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.361) total time=   3.1s\n",
      "[CV 1/5; 11/16] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 11/16] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.972, test=0.371) total time=   3.5s\n",
      "[CV 2/5; 11/16] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 11/16] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.410) total time=   3.1s\n",
      "[CV 3/5; 11/16] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 11/16] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.367) total time=   3.3s\n",
      "[CV 4/5; 11/16] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 11/16] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.545) total time=   3.1s\n",
      "[CV 5/5; 11/16] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 11/16] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.377) total time=   3.3s\n",
      "[CV 1/5; 12/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.978, test=0.430) total time=   3.4s\n",
      "[CV 2/5; 12/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 12/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.986, test=0.394) total time=   3.1s\n",
      "[CV 3/5; 12/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 12/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.424) total time=   3.2s\n",
      "[CV 4/5; 12/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.355) total time=   3.0s\n",
      "[CV 5/5; 12/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.991, test=0.444) total time=   3.1s\n",
      "[CV 1/5; 13/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 13/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.440) total time=   3.2s\n",
      "[CV 2/5; 13/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 13/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.956, test=0.402) total time=   2.9s\n",
      "[CV 3/5; 13/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 13/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.414) total time=   3.1s\n",
      "[CV 4/5; 13/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 13/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.467) total time=   2.8s\n",
      "[CV 5/5; 13/16] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 13/16] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.991, test=0.448) total time=   3.0s\n",
      "[CV 1/5; 14/16] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 14/16] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.302) total time=   3.2s\n",
      "[CV 2/5; 14/16] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 14/16] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.463) total time=   2.8s\n",
      "[CV 3/5; 14/16] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 14/16] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.325) total time=   3.0s\n",
      "[CV 4/5; 14/16] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 14/16] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.431) total time=   2.8s\n",
      "[CV 5/5; 14/16] START Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 14/16] END Selection__percentile=80, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.382) total time=   3.0s\n",
      "[CV 1/5; 15/16] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 15/16] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.440) total time=   3.4s\n",
      "[CV 2/5; 15/16] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 15/16] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.426) total time=   3.0s\n",
      "[CV 3/5; 15/16] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 15/16] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.415) total time=   3.2s\n",
      "[CV 4/5; 15/16] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 15/16] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.373) total time=   2.9s\n",
      "[CV 5/5; 15/16] START Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 15/16] END Selection__percentile=80, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.283) total time=   3.1s\n",
      "[CV 1/5; 16/16] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 16/16] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.970, test=0.403) total time=   3.4s\n",
      "[CV 2/5; 16/16] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 16/16] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.403) total time=   3.0s\n",
      "[CV 3/5; 16/16] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 16/16] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.286) total time=   3.2s\n",
      "[CV 4/5; 16/16] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 16/16] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.453) total time=   3.0s\n",
      "[CV 5/5; 16/16] START Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 16/16] END Selection__percentile=20, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.440) total time=   3.1s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 810\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5; 1/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.744, test=0.434) total time=   9.5s\n",
      "[CV 2/5; 1/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.756, test=0.395) total time=   9.6s\n",
      "[CV 3/5; 1/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.757, test=0.397) total time=   9.8s\n",
      "[CV 4/5; 1/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.757, test=0.473) total time=   9.4s\n",
      "[CV 5/5; 1/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.769, test=0.396) total time=   9.6s\n",
      "[CV 1/5; 2/6] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 1/5; 2/6] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.999, test=0.339) total time=   9.7s\n",
      "[CV 2/5; 2/6] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 2/5; 2/6] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.999, test=0.444) total time=   9.9s\n",
      "[CV 3/5; 2/6] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 3/5; 2/6] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.379) total time=  10.0s\n",
      "[CV 4/5; 2/6] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 4/5; 2/6] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=0.999, test=0.350) total time=   9.6s\n",
      "[CV 5/5; 2/6] START Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3)\n",
      "[CV 5/5; 2/6] END Selection__percentile=20, clf=RandomForestClassifier(random_state=50), clf__n_estimators=100, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 3);, score=(train=1.000, test=0.361) total time=   9.9s\n",
      "[CV 1/5; 3/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.721, test=0.454) total time=   9.0s\n",
      "[CV 2/5; 3/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.745, test=0.399) total time=   9.1s\n",
      "[CV 3/5; 3/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.784, test=0.416) total time=   9.2s\n",
      "[CV 4/5; 3/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.765, test=0.460) total time=   8.8s\n",
      "[CV 5/5; 3/6] START Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/6] END Selection__percentile=40, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.752, test=0.435) total time=   9.2s\n",
      "[CV 1/5; 4/6] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/6] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.973, test=0.483) total time=   8.6s\n",
      "[CV 2/5; 4/6] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/6] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.937, test=0.430) total time=   8.7s\n",
      "[CV 3/5; 4/6] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/6] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.983, test=0.428) total time=   8.8s\n",
      "[CV 4/5; 4/6] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/6] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.942, test=0.552) total time=   8.5s\n",
      "[CV 5/5; 4/6] START Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/6] END Selection__percentile=80, clf=LogisticRegression(random_state=50), clf__C=1000, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=0.933, test=0.441) total time=   8.8s\n",
      "[CV 1/5; 5/6] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 1/5; 5/6] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.999, test=0.371) total time=  11.9s\n",
      "[CV 2/5; 5/6] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 2/5; 5/6] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.373) total time=  11.9s\n",
      "[CV 3/5; 5/6] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 3/5; 5/6] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.377) total time=  12.0s\n",
      "[CV 4/5; 5/6] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 4/5; 5/6] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=0.999, test=0.376) total time=  11.7s\n",
      "[CV 5/5; 5/6] START Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2)\n",
      "[CV 5/5; 5/6] END Selection__percentile=40, clf=RandomForestClassifier(random_state=50), clf__n_estimators=1000, preprocessing__bow__min_df=0.1, preprocessing__bow__ngram_range=(1, 2);, score=(train=1.000, test=0.382) total time=  11.9s\n",
      "[CV 1/5; 6/6] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 1/5; 6/6] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.369) total time=   8.7s\n",
      "[CV 2/5; 6/6] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 2/5; 6/6] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.383) total time=   8.7s\n",
      "[CV 3/5; 6/6] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 3/5; 6/6] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.425) total time=   8.7s\n",
      "[CV 4/5; 6/6] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 4/5; 6/6] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.436) total time=   8.5s\n",
      "[CV 5/5; 6/6] START Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1)\n",
      "[CV 5/5; 6/6] END Selection__percentile=60, clf=DecisionTreeClassifier(random_state=50), clf__criterion=gini, preprocessing__bow__min_df=0.05, preprocessing__bow__ngram_range=(1, 1);, score=(train=1.000, test=0.433) total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\mds7202\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingGridSearchCV(estimator=Pipeline(steps=[('preprocessing',\n",
       "                                               ColumnTransformer(transformers=[('bow',\n",
       "                                                                                CountVectorizer(ngram_range=(1,\n",
       "                                                                                                             2),\n",
       "                                                                                                tokenizer=<__main__.StemmerTokenizer object at 0x000001EE137904C0>),\n",
       "                                                                                'history_text'),\n",
       "                                                                               ('MinMaxScaler',\n",
       "                                                                                MinMaxScaler(),\n",
       "                                                                                ['intelligence_score',\n",
       "                                                                                 'strength_score',\n",
       "                                                                                 'speed_score',\n",
       "                                                                                 'durability_score',\n",
       "                                                                                 'power_score',\n",
       "                                                                                 'combat_score'])...\n",
       "                                 'clf__C': [0.01, 1000],\n",
       "                                 'preprocessing__bow__min_df': [0.05, 0.1],\n",
       "                                 'preprocessing__bow__ngram_range': [(1, 1),\n",
       "                                                                     (1, 2),\n",
       "                                                                     (1, 3)]},\n",
       "                                {'Selection__percentile': [20, 40, 60, 80],\n",
       "                                 'clf': [RandomForestClassifier(random_state=50)],\n",
       "                                 'clf__n_estimators': [100, 1000],\n",
       "                                 'preprocessing__bow__min_df': [0.05, 0.1],\n",
       "                                 'preprocessing__bow__ngram_range': [(1, 1),\n",
       "                                                                     (1, 2),\n",
       "                                                                     (1, 3)]}],\n",
       "                    scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "\n",
    "hgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.57      0.59      0.58       138\n",
      "        Good       0.78      0.74      0.76       261\n",
      "     Neutral       0.11      0.15      0.13        26\n",
      "\n",
      "    accuracy                           0.65       425\n",
      "   macro avg       0.49      0.49      0.49       425\n",
      "weighted avg       0.67      0.65      0.66       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicción\n",
    "\n",
    "y_pred = hgs.predict(X_test)\n",
    "\n",
    "# Métricas de evaluación \n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9548ab417c8847e4a3d10235845e1ece",
    "deepnote_cell_height": 70.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "```\n",
    "Fue costoso realizar esta parte de la tarea y hacer una elección de hiperparámetros a modificar que no generara problemas para ejecturar el grid search de manera local (por eso algunos paramétros terminé dejándolos como comentarios).\n",
    "\n",
    "Ahora bien, los resultados en accuracy se subió apenas de un 0.61 a 0.65, pero en las métricas de precision, recall y f1-score de las clases Bad y Good se obtuvieron mejores resultados. Lamentablemente para la clase Neutral fue muy poco lo que se pudo subir.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00042-1dc5444c-59e9-4d79-93fb-3c545fe3b086",
    "deepnote_cell_height": 600.15625,
    "deepnote_cell_type": "markdown",
    "id": "OmQUw2aZ_6z2"
   },
   "source": [
    "## 1.4 Predicción del datos sin etiquetado  [0.5 puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-bdf593d2-92b5-4d74-869a-8c9541a6e572",
    "deepnote_cell_height": 111.171875,
    "deepnote_cell_type": "markdown",
    "id": "Cj0ERBgTBFWN"
   },
   "source": [
    "LLego el momento de predecir \n",
    "`Vergil`, `Gorilla Girl` y `Batcow`\n",
    "\n",
    "\n",
    "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-1e9b40e0-20dc-4ed1-81ca-b7f8f9679771",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "00035-1ec91701-af2f-4571-9067-f82dbc6f2989",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>real_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>history_text</th>\n",
       "      <th>powers_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>...</th>\n",
       "      <th>has_flight</th>\n",
       "      <th>has_accelerated_healing</th>\n",
       "      <th>has_weapons_master</th>\n",
       "      <th>has_intelligence</th>\n",
       "      <th>has_reflexes</th>\n",
       "      <th>has_super_speed</th>\n",
       "      <th>has_durability</th>\n",
       "      <th>has_stamina</th>\n",
       "      <th>has_agility</th>\n",
       "      <th>has_super_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>514A (Gotham)</td>\n",
       "      <td>Bruce Wayne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>He was one of the many prisoners of Indian Hil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>Ace Morgan</td>\n",
       "      <td>Kyle Morgan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aviation:  Ace is an extremely skilled pilot, ...</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>A'dal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>As with most of the naaru, little is known of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>Agent Zero (FOX)</td>\n",
       "      <td>David North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>During mid-late 1973, Zero was a member of Tea...</td>\n",
       "      <td>Zero can absorb kinetic energy to further incr...</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>Ajax (FOX)</td>\n",
       "      <td>Francis</td>\n",
       "      <td>Francis Freeman</td>\n",
       "      <td>7</td>\n",
       "      <td>Ajax (born Francis Freeman) was a human who ga...</td>\n",
       "      <td>Ajax has claimed that the procedure to obtain ...</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              name    real_name        full_name overall_score  \\\n",
       "0           1     514A (Gotham)  Bruce Wayne              NaN            10   \n",
       "1          14        Ace Morgan  Kyle Morgan              NaN             7   \n",
       "2          17             A'dal          NaN              NaN             7   \n",
       "3          27  Agent Zero (FOX)  David North              NaN             6   \n",
       "4          31        Ajax (FOX)      Francis  Francis Freeman             7   \n",
       "\n",
       "                                        history_text  \\\n",
       "0  He was one of the many prisoners of Indian Hil...   \n",
       "1                                                NaN   \n",
       "2  As with most of the naaru, little is known of ...   \n",
       "3  During mid-late 1973, Zero was a member of Tea...   \n",
       "4  Ajax (born Francis Freeman) was a human who ga...   \n",
       "\n",
       "                                         powers_text  intelligence_score  \\\n",
       "0                                                NaN                 100   \n",
       "1  Aviation:  Ace is an extremely skilled pilot, ...                  85   \n",
       "2                                                NaN                  85   \n",
       "3  Zero can absorb kinetic energy to further incr...                  90   \n",
       "4  Ajax has claimed that the procedure to obtain ...                  85   \n",
       "\n",
       "   strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
       "0              20           30  ...         0.0                      0.0   \n",
       "1              20           65  ...         0.0                      0.0   \n",
       "2              30           70  ...         0.0                      0.0   \n",
       "3              10           25  ...         0.0                      0.0   \n",
       "4              25           45  ...         0.0                      0.0   \n",
       "\n",
       "   has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
       "0                 0.0              0.0          1.0             0.0   \n",
       "1                 1.0              1.0          1.0             0.0   \n",
       "2                 0.0              0.0          0.0             0.0   \n",
       "3                 0.0              0.0          1.0             0.0   \n",
       "4                 1.0              1.0          1.0             0.0   \n",
       "\n",
       "  has_durability has_stamina has_agility  has_super_strength  \n",
       "0            1.0         0.0         0.0                 1.0  \n",
       "1            0.0         1.0         1.0                 0.0  \n",
       "2            0.0         0.0         0.0                 0.0  \n",
       "3            0.0         0.0         1.0                 0.0  \n",
       "4            1.0         0.0         0.0                 1.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Código aquí ####\n",
    "df_comics_no_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>history_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>durability_score</th>\n",
       "      <th>power_score</th>\n",
       "      <th>combat_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>514A (Gotham)</td>\n",
       "      <td>He was one of the many prisoners of Indian Hil...</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A'dal</td>\n",
       "      <td>As with most of the naaru, little is known of ...</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agent Zero (FOX)</td>\n",
       "      <td>During mid-late 1973, Zero was a member of Tea...</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ajax (FOX)</td>\n",
       "      <td>Ajax (born Francis Freeman) was a human who ga...</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A.M.A.Z.O. (CW)</td>\n",
       "      <td>The Anti Meta-human Adaptive Zootomic Organism...</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Wendigo</td>\n",
       "      <td>The Wendigo are the result of an ancient curse...</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>XS (CW)</td>\n",
       "      <td>According to Eobard Thawne, the daughter of Ba...</td>\n",
       "      <td>90</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Yondu (MCU)</td>\n",
       "      <td>Yondu Udonta was a Centaurian, leader of a key...</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Batcow</td>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                                       history_text  \\\n",
       "0      514A (Gotham)  He was one of the many prisoners of Indian Hil...   \n",
       "2              A'dal  As with most of the naaru, little is known of ...   \n",
       "3   Agent Zero (FOX)  During mid-late 1973, Zero was a member of Tea...   \n",
       "4         Ajax (FOX)  Ajax (born Francis Freeman) was a human who ga...   \n",
       "6    A.M.A.Z.O. (CW)  The Anti Meta-human Adaptive Zootomic Organism...   \n",
       "..               ...                                                ...   \n",
       "78            Vergil  Vergil, later also known as Nelo Angelo, is on...   \n",
       "80           Wendigo  The Wendigo are the result of an ancient curse...   \n",
       "81           XS (CW)  According to Eobard Thawne, the daughter of Ba...   \n",
       "82       Yondu (MCU)  Yondu Udonta was a Centaurian, leader of a key...   \n",
       "83            Batcow  Bat-Cow was originally a cow that was found by...   \n",
       "\n",
       "    intelligence_score  strength_score  speed_score  durability_score  \\\n",
       "0                  100              20           30                50   \n",
       "2                   85              30           70                55   \n",
       "3                   90              10           25                25   \n",
       "4                   85              25           45                75   \n",
       "6                   90             100          100               100   \n",
       "..                 ...             ...          ...               ...   \n",
       "78                  90              75           95                90   \n",
       "80                  65              80           75                75   \n",
       "81                  90              55          100                60   \n",
       "82                  85              25           40                40   \n",
       "83                  70              10           25                20   \n",
       "\n",
       "    power_score  combat_score  \n",
       "0            35           100  \n",
       "2            65           100  \n",
       "3            35            80  \n",
       "4            45            65  \n",
       "6           100           100  \n",
       "..          ...           ...  \n",
       "78          100           100  \n",
       "80           90            70  \n",
       "81          100            65  \n",
       "82           60            80  \n",
       "83           10            20  \n",
       "\n",
       "[76 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data a predecir\n",
    "df = df_comics_no_label[['name','history_text',\n",
    "                        'intelligence_score',\n",
    "                        'strength_score', \n",
    "                        'speed_score',\n",
    "                        'durability_score',\n",
    "                        'power_score',\n",
    "                        'combat_score']]\n",
    "df = df.dropna(subset=['history_text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "history_text\n",
       "False           76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['history_text']].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    No hay nans en history_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>history_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>durability_score</th>\n",
       "      <th>power_score</th>\n",
       "      <th>combat_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Batcow</td>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Gorilla Girl</td>\n",
       "      <td>A carnival performer with the ability to turn ...</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Batcow</td>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                       history_text  \\\n",
       "16        Batcow  Bat-Cow was originally a cow that was found by...   \n",
       "40  Gorilla Girl  A carnival performer with the ability to turn ...   \n",
       "78        Vergil  Vergil, later also known as Nelo Angelo, is on...   \n",
       "83        Batcow  Bat-Cow was originally a cow that was found by...   \n",
       "\n",
       "    intelligence_score  strength_score  speed_score  durability_score  \\\n",
       "16                  70              10           25                20   \n",
       "40                  90              35           60                60   \n",
       "78                  90              75           95                90   \n",
       "83                  70              10           25                20   \n",
       "\n",
       "    power_score  combat_score  \n",
       "16           10            20  \n",
       "40           45           100  \n",
       "78          100           100  \n",
       "83           10            20  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personajes = df[df[\"name\"].isin([\"Vergil\",\"Gorilla Girl\",\"Batcow\"])]\n",
    "df_personajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>history_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>durability_score</th>\n",
       "      <th>power_score</th>\n",
       "      <th>combat_score</th>\n",
       "      <th>Predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Batcow</td>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Gorilla Girl</td>\n",
       "      <td>A carnival performer with the ability to turn ...</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                       history_text  \\\n",
       "16        Batcow  Bat-Cow was originally a cow that was found by...   \n",
       "40  Gorilla Girl  A carnival performer with the ability to turn ...   \n",
       "78        Vergil  Vergil, later also known as Nelo Angelo, is on...   \n",
       "\n",
       "    intelligence_score  strength_score  speed_score  durability_score  \\\n",
       "16                  70              10           25                20   \n",
       "40                  90              35           60                60   \n",
       "78                  90              75           95                90   \n",
       "\n",
       "    power_score  combat_score Predicción  \n",
       "16           10            20       Good  \n",
       "40           45           100       Good  \n",
       "78          100           100       Good  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personajes = df_personajes.drop_duplicates()#.drop([\"name\"],axis=1) # se elimina duplicados\n",
    "df_personajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>history_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>durability_score</th>\n",
       "      <th>power_score</th>\n",
       "      <th>combat_score</th>\n",
       "      <th>Predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A carnival performer with the ability to turn ...</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         history_text  intelligence_score  \\\n",
       "16  Bat-Cow was originally a cow that was found by...                  70   \n",
       "40  A carnival performer with the ability to turn ...                  90   \n",
       "78  Vergil, later also known as Nelo Angelo, is on...                  90   \n",
       "\n",
       "    strength_score  speed_score  durability_score  power_score  combat_score  \\\n",
       "16              10           25                20           10            20   \n",
       "40              35           60                60           45           100   \n",
       "78              75           95                90          100           100   \n",
       "\n",
       "   Predicción  \n",
       "16       Good  \n",
       "40       Good  \n",
       "78       Good  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_personajes.drop_duplicates().drop([\"name\"],axis=1) # se elimina columna name\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>history_text</th>\n",
       "      <th>intelligence_score</th>\n",
       "      <th>strength_score</th>\n",
       "      <th>speed_score</th>\n",
       "      <th>durability_score</th>\n",
       "      <th>power_score</th>\n",
       "      <th>combat_score</th>\n",
       "      <th>Predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A carnival performer with the ability to turn ...</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         history_text  intelligence_score  \\\n",
       "16  Bat-Cow was originally a cow that was found by...                  70   \n",
       "40  A carnival performer with the ability to turn ...                  90   \n",
       "78  Vergil, later also known as Nelo Angelo, is on...                  90   \n",
       "\n",
       "    strength_score  speed_score  durability_score  power_score  combat_score  \\\n",
       "16              10           25                20           10            20   \n",
       "40              35           60                60           45           100   \n",
       "78              75           95                90          100           100   \n",
       "\n",
       "   Predicción  \n",
       "16       Good  \n",
       "40       Good  \n",
       "78       Good  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se hace la predicción\n",
    "\n",
    "df_final[\"Predicción\"] = hgs.predict(df_final)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Batcow</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Gorilla Girl</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name Predicción\n",
       "16        Batcow       Good\n",
       "40  Gorilla Girl       Good\n",
       "78        Vergil       Good"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ df_personajes[['name']], df_final[[\"Predicción\"]] ], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bat-Cow was originally a cow that was found by Robin during an investigation on a slaughterhouse, which the cow was sent to. Robin wanted to keep the cow and named it Bat-Cow. Batman decided they would keep the cow. During a later investigation, Batman discovered it had mind-controlling radiation inside of it, leading him to attempt to get rid of the cow. Robin, however would not allow him to hurt the cow. After the events of Robin\\'s death, Bat-Cow and Robin\\'s dog felt a great loss in morale. Alfred Pennyworth and Nightwing had to take care of the cow. Later after Nightwing\\'s disappearance, Alfred was the only caretaker of Bat-Cow. Bat-Cow, complete with cape, spent time on a Wayne Enterprises-owned dairy farm. It was there the cow encountered the cosmic-powered \"Forever People.\" One of them seemed to gain guidance from Bat-Cow\\'s actions, namely when Bat-Cow gave one of the Forever People a scarecrow\\'s hat. Bat-Cow formed a friendship with Titus, a dog and household cat.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['history_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finalmente se concluye que todos eran wenitos :) La historia de Batcow no es para nada una historia de villanos así que estamo' agree con la predicción :)\n",
    "    \n",
    "    ¡Saludos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00045-bf830861-7edd-434b-93f5-af4b0404ce83",
    "deepnote_cell_height": 269,
    "deepnote_cell_type": "markdown",
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LCOUC4jss148",
    "GtG74Cphq56p"
   ],
   "name": "Laboratorio4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "038fcdf2-d87a-4a74-89c6-f5afff22afb6",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
